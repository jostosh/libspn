{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libspn as spn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Test Graph with Random Weights\n",
    "So, what does generate_ivs do? Basically it connects an IV to a sum node (it is a method defined in `SumNode`). Can be used for a latent variable interpretation.\n",
    "```python\n",
    "def generate_ivs(self, feed=None, name=None):\n",
    "    \"\"\"Generate an IVs node matching this sum node and connect it to\n",
    "    this sum.\n",
    "\n",
    "    IVs should be generated once all inputs are added to this node,\n",
    "    otherwise the number of IVs will be incorrect.\n",
    "\n",
    "    Args:\n",
    "        feed (Tensor): See :class:`~libspn.IVs`.\n",
    "        name (str): Name of the IVs node. If ``None`` use the name of the\n",
    "                    sum + ``_IVs``.\n",
    "\n",
    "    Return:\n",
    "        IVs: Generated IVs node.\n",
    "    \"\"\"\n",
    "    if not self._values:\n",
    "        raise StructureError(\"%s is missing input values\" % self)\n",
    "    if name is None:\n",
    "        name = self._name + \"_IVs\"\n",
    "    # Count all input values\n",
    "    num_values = sum(len(v.indices) if v.indices is not None\n",
    "                     else v.node.get_out_size()\n",
    "                     for v in self._values)\n",
    "    ivs = IVs(feed=feed, num_vars=1, num_vals=num_values, name=name)\n",
    "    self.set_ivs(ivs)\n",
    "    return ivs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_x = spn.IVs(num_vars=2, num_vals=2, name=\"iv_x\")\n",
    "sum_11 = spn.Sum((iv_x, [0,1]), name=\"sum_11\")\n",
    "sum_12 = spn.Sum((iv_x, [0,1]), name=\"sum_12\")\n",
    "sum_21 = spn.Sum((iv_x, [2,3]), name=\"sum_21\")\n",
    "sum_22 = spn.Sum((iv_x, [2,3]), name=\"sum_22\")\n",
    "prod_1 = spn.Product(sum_11, sum_21, name=\"prod_1\")\n",
    "prod_2 = spn.Product(sum_11, sum_22, name=\"prod_2\")\n",
    "prod_3 = spn.Product(sum_12, sum_22, name=\"prod_3\")\n",
    "root = spn.Sum(prod_1, prod_2, prod_3, name=\"root\")\n",
    "# Some latent variable\n",
    "iv_y = root.generate_ivs(name=\"iv_y\")\n",
    "# initialize weights randomly\n",
    "spn.generate_weights(root, init_value=spn.ValueType.RANDOM_UNIFORM(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the SPN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg id=\"S3755aaec45134e4bb20fbec6f127a2d6\" width=\"950\" height=\"800\"></svg>\n",
       "<script>\n",
       " require.config({\n",
       "   paths: {\n",
       "     d3: 'https://d3js.org/d3.v4.min'\n",
       "   }\n",
       " });\n",
       " require(['d3'], function(d3){\n",
       "\n",
       "   var graph = {\"links\": [{\"value\": 2, \"target\": \"sum_22\", \"source\": \"Weights/sum_22_Weights_1\"}, {\"value\": 2, \"target\": \"sum_22\", \"source\": \"iv_x_2\"}, {\"value\": 2, \"target\": \"sum_12\", \"source\": \"Weights/sum_12_Weights_3\"}, {\"value\": 2, \"target\": \"sum_12\", \"source\": \"iv_x_4\"}, {\"value\": 1, \"target\": \"prod_3\", \"source\": \"sum_12\"}, {\"value\": 1, \"target\": \"prod_3\", \"source\": \"sum_22\"}, {\"value\": 2, \"target\": \"sum_11\", \"source\": \"Weights/sum_11_Weights_5\"}, {\"value\": 2, \"target\": \"sum_11\", \"source\": \"iv_x_6\"}, {\"value\": 1, \"target\": \"prod_2\", \"source\": \"sum_11\"}, {\"value\": 1, \"target\": \"prod_2\", \"source\": \"sum_22\"}, {\"value\": 2, \"target\": \"sum_21\", \"source\": \"Weights/sum_21_Weights_7\"}, {\"value\": 2, \"target\": \"sum_21\", \"source\": \"iv_x_8\"}, {\"value\": 1, \"target\": \"prod_1\", \"source\": \"sum_11\"}, {\"value\": 1, \"target\": \"prod_1\", \"source\": \"sum_21\"}, {\"value\": 3, \"target\": \"root\", \"source\": \"Weights/root_Weights_9\"}, {\"value\": 3, \"target\": \"root\", \"source\": \"iv_y_10\"}, {\"value\": 1, \"target\": \"root\", \"source\": \"prod_1\"}, {\"value\": 1, \"target\": \"root\", \"source\": \"prod_2\"}, {\"value\": 1, \"target\": \"root\", \"source\": \"prod_3\"}], \"nodes\": [{\"id\": \"sum_22\", \"tooltip\": \"sum_22\", \"type\": 2, \"name\": \"sum_22\"}, {\"id\": \"Weights/sum_22_Weights_1\", \"tooltip\": \"Weights/sum_22_Weights\", \"type\": 1, \"name\": \"Weights/sum_22_Weights\"}, {\"id\": \"iv_x_2\", \"tooltip\": \"iv_x\", \"type\": 0, \"name\": \"iv_x[2, 3]\"}, {\"id\": \"sum_12\", \"tooltip\": \"sum_12\", \"type\": 2, \"name\": \"sum_12\"}, {\"id\": \"Weights/sum_12_Weights_3\", \"tooltip\": \"Weights/sum_12_Weights\", \"type\": 1, \"name\": \"Weights/sum_12_Weights\"}, {\"id\": \"iv_x_4\", \"tooltip\": \"iv_x\", \"type\": 0, \"name\": \"iv_x[0, 1]\"}, {\"id\": \"prod_3\", \"tooltip\": \"prod_3\", \"type\": 3, \"name\": \"prod_3\"}, {\"id\": \"sum_11\", \"tooltip\": \"sum_11\", \"type\": 2, \"name\": \"sum_11\"}, {\"id\": \"Weights/sum_11_Weights_5\", \"tooltip\": \"Weights/sum_11_Weights\", \"type\": 1, \"name\": \"Weights/sum_11_Weights\"}, {\"id\": \"iv_x_6\", \"tooltip\": \"iv_x\", \"type\": 0, \"name\": \"iv_x[0, 1]\"}, {\"id\": \"prod_2\", \"tooltip\": \"prod_2\", \"type\": 3, \"name\": \"prod_2\"}, {\"id\": \"sum_21\", \"tooltip\": \"sum_21\", \"type\": 2, \"name\": \"sum_21\"}, {\"id\": \"Weights/sum_21_Weights_7\", \"tooltip\": \"Weights/sum_21_Weights\", \"type\": 1, \"name\": \"Weights/sum_21_Weights\"}, {\"id\": \"iv_x_8\", \"tooltip\": \"iv_x\", \"type\": 0, \"name\": \"iv_x[2, 3]\"}, {\"id\": \"prod_1\", \"tooltip\": \"prod_1\", \"type\": 3, \"name\": \"prod_1\"}, {\"id\": \"root\", \"tooltip\": \"root\", \"type\": 2, \"name\": \"root\"}, {\"id\": \"Weights/root_Weights_9\", \"tooltip\": \"Weights/root_Weights\", \"type\": 1, \"name\": \"Weights/root_Weights\"}, {\"id\": \"iv_y_10\", \"tooltip\": \"iv_y\", \"type\": 0, \"name\": \"iv_y\"}]};\n",
       "\n",
       "   var color = d3.scaleOrdinal(d3.schemeCategory10);\n",
       "\n",
       "   var zoom = d3.zoom()\n",
       "                .scaleExtent([0.1, 10])\n",
       "                .on(\"zoom\", zoomed);\n",
       "\n",
       "   var svg = d3.select(\"#S3755aaec45134e4bb20fbec6f127a2d6\").\n",
       "                call(zoom);\n",
       "\n",
       "   var width = svg.attr(\"width\");\n",
       "   var height = svg.attr(\"height\");\n",
       "\n",
       "   var simulation = d3.forceSimulation(graph.nodes)\n",
       "                      .on(\"tick\", ticked)\n",
       "                      .force(\"link\", d3.forceLink(graph.links)\n",
       "                                       .distance(80)\n",
       "                                       .id(function(d) { return d.id; }))\n",
       "                      .force(\"charge\", d3.forceManyBody().\n",
       "                                          strength(-1000))\n",
       "                      .force(\"center\", d3.forceCenter(width / 2, height / 2));\n",
       "\n",
       "   /* Contents */\n",
       "   var container = svg.append(\"g\").\n",
       "                       attr(\"class\", \"container\");\n",
       "\n",
       "   var link = container.append(\"g\")\n",
       "                       .selectAll(\"link\")\n",
       "                       .data(graph.links)\n",
       "                       .enter().append(\"line\")\n",
       "                       .attr(\"stroke\", \"#444\")\n",
       "                       .attr(\"stroke-opacity\", \"0.6\")\n",
       "                       .attr(\"stroke-width\",\n",
       "                             function(d) {\n",
       "                               return d.value;\n",
       "                               /*return Math.sqrt(d.value);*/\n",
       "                             });\n",
       "\n",
       "   var link_value = container.append(\"g\")\n",
       "                             .selectAll(\"linkvalue\")\n",
       "                             .data(graph.links)\n",
       "                             .enter().append(\"text\")\n",
       "                             .attr(\"alignment-baseline\", \"middle\")\n",
       "                             .style(\"text-anchor\", \"middle\")\n",
       "                             .text(function(d) { return d.value; });\n",
       "\n",
       "   var node = container.append(\"g\")\n",
       "                       .selectAll(\"node\")\n",
       "                       .data(graph.nodes)\n",
       "                       .enter().append(\"g\")\n",
       "                       .call(d3.drag()\n",
       "                               .on(\"start\", dragstarted)\n",
       "                               .on(\"drag\", dragged)\n",
       "                               .on(\"end\", dragended));\n",
       "\n",
       "   /* Node appearance */\n",
       "   node.append(\"rect\")\n",
       "       .attr(\"height\", 0)\n",
       "       .attr(\"width\", 0)\n",
       "       .attr(\"fill\", function(d) { return color(d.type); })\n",
       "       .attr(\"stroke\", \"#000\")\n",
       "       .attr(\"stroke-width\", \"1px\");\n",
       "\n",
       "   node.append(\"text\")\n",
       "       .attr(\"alignment-baseline\", \"middle\")\n",
       "       .style(\"text-anchor\", \"middle\")\n",
       "       .text(function(d) { return d.name; });\n",
       "\n",
       "   /* Adjust rect width to text */\n",
       "   var margin=10;\n",
       "   node.selectAll('rect')\n",
       "       .attr(\"x\", function(d) {return d3.select(this).attr(\"x\") - (this.parentNode.getBBox().width + margin)/2.0;})\n",
       "       .attr(\"y\", function(d) {return d3.select(this).attr(\"y\") - (this.parentNode.getBBox().height + margin)/2.0;})\n",
       "       .attr(\"width\", function(d) {return this.parentNode.getBBox().width + margin;})\n",
       "       .attr(\"height\", function(d) {return this.parentNode.getBBox().height + margin;});\n",
       "\n",
       "   /* Tooltips */\n",
       "   node.append(\"title\")\n",
       "       .text(function(d) { return d.tooltip; });\n",
       "\n",
       "   /* Functions */\n",
       "   function zoomed() {\n",
       "     container.attr(\"transform\", d3.event.transform);\n",
       "   }\n",
       "\n",
       "   function ticked() {\n",
       "     link\n",
       "       .attr(\"x1\", function(d) { return d.source.x; })\n",
       "       .attr(\"y1\", function(d) { return d.source.y; })\n",
       "       .attr(\"x2\", function(d) { return d.target.x; })\n",
       "       .attr(\"y2\", function(d) { return d.target.y; });\n",
       "\n",
       "     link_value\n",
       "       .attr(\"x\", function(d) { return (d.source.x+d.target.x)/2; })\n",
       "       .attr(\"y\", function(d) { return (d.source.y+d.target.y)/2; })\n",
       "\n",
       "     node.attr(\"transform\",\n",
       "               function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "   }\n",
       "\n",
       "   function dragstarted(d) {\n",
       "     if (!d3.event.active) simulation.alphaTarget(0.3).restart();\n",
       "     d.fx = d.x;\n",
       "     d.fy = d.y;\n",
       "   }\n",
       "\n",
       "   function dragged(d) {\n",
       "     d.fx = d3.event.x;\n",
       "     d.fy = d3.event.y;\n",
       "   }\n",
       "\n",
       "   function dragended(d) {\n",
       "     if (!d3.event.active) simulation.alphaTarget(0);\n",
       "     d.fx = null;\n",
       "     d.fy = null;\n",
       "   }\n",
       "\n",
       " });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spn.display_spn_graph(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_x_arr=[\n",
    "    [0,0], # in two cases x1 = x2 = 0 \n",
    "    [0,0],\n",
    "    [1,1], # in three cases x1 = x2 = 1\n",
    "    [1,1],\n",
    "    [1,1],\n",
    "    [0,1], # in three cases x1 = 0 and x2 = 1\n",
    "    [0,1],\n",
    "    [0,1]\n",
    "]\n",
    "# no evidence for iv_y\n",
    "iv_y_arr=[[-1]] * len(iv_x_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Learning Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build initialization op\n",
    "init_weights = spn.initialize_weights(root)\n",
    "\n",
    "# Build learning op\n",
    "learning = spn.EMLearning(root, initial_accum_value=2)\n",
    "init_learning = learning.reset_accumulators()\n",
    "accumulate_updates = learning.accumulate_updates()\n",
    "update_spn = learning.update_spn()\n",
    "likelihood = tf.reduce_mean(learning.value.values[root])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at `EMLearning`:\n",
    "```python\n",
    "class EMLearning():\n",
    "    \"\"\"Assembles TF operations performing EM learning of an SPN.\n",
    "\n",
    "    Args:\n",
    "        mpe_path (MPEPath): Pre-computed MPE_path.\n",
    "        value_inference_type (InferenceType): The inference type used during the\n",
    "            upwards pass through the SPN. Ignored if ``mpe_path`` is given.\n",
    "        log (bool): If ``True``, calculate the value in the log space. Ignored\n",
    "                    if ``mpe_path`` is given.\n",
    "    \"\"\"\n",
    "\n",
    "    ParamNode = namedtuple(\"ParamNode\", [\"node\", \"name_scope\", \"accum\"])\n",
    "\n",
    "    def __init__(self, root, mpe_path=None, log=True, value_inference_type=None,\n",
    "                 additive_smoothing=None, add_random=None, initial_accum_value=None,\n",
    "                 use_unweighted=False):\n",
    "        self._root = root\n",
    "        self._additive_smoothing = additive_smoothing\n",
    "        self._initial_accum_value = initial_accum_value\n",
    "        # Create internal MPE path generator\n",
    "        if mpe_path is None:\n",
    "            \"\"\" In the example above this is not given, so MPEPath is built here \"\"\"\n",
    "            \n",
    "            self._mpe_path = MPEPath(log=log,\n",
    "                                     value_inference_type=value_inference_type,\n",
    "                                     add_random=add_random, use_unweighted=use_unweighted)\n",
    "        else:\n",
    "            self._mpe_path = mpe_path\n",
    "        # Create a name scope\n",
    "        with tf.name_scope(\"EMLearning\") as self._name_scope:\n",
    "            pass\n",
    "        # Create accumulators\n",
    "        self._create_accumulators()\n",
    "\n",
    "```\n",
    "The initialization of `MPEPath` is given here:\n",
    "```python\n",
    "class MPEPath:\n",
    "    \"\"\"Assembles TF operations computing the branch counts for the MPE downward\n",
    "    path through the SPN. It computes the number of times each branch was\n",
    "    traveled by a complete subcircuit determined by the MPE value of the latent\n",
    "    variables in the model.\n",
    "\n",
    "    Args:\n",
    "        value (Value or LogValue): Pre-computed SPN values.\n",
    "        value_inference_type (InferenceType): The inference type used during the\n",
    "            upwards pass through the SPN. Ignored if ``value`` is given.\n",
    "        log (bool): If ``True``, calculate the value in the log space. Ignored\n",
    "                    if ``value`` is given.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, value=None, value_inference_type=None, log=True, add_random=None,\n",
    "                 use_unweighted=False):\n",
    "        self._counts = {}\n",
    "        self._log = log\n",
    "        self._add_random = add_random\n",
    "        self._use_unweighted = use_unweighted\n",
    "        # Create internal value generator\n",
    "        if value is None:\n",
    "            if log:\n",
    "                \"\"\" Log value is used by default \"\"\"\n",
    "                self._value = LogValue(value_inference_type)\n",
    "            else:\n",
    "                self._value = Value(value_inference_type)\n",
    "        else:\n",
    "            self._value = value\n",
    "```\n",
    "\n",
    "Final call in constructor of EMLearning is `_create_accumulators()`\n",
    "```python\n",
    "def _create_accumulators(self):\n",
    "    def fun(node):\n",
    "        # Only cares about parameter nodes\n",
    "        if node.is_param:\n",
    "            with tf.name_scope(node.name) as scope:\n",
    "                if self._initial_accum_value is not None:\n",
    "                    # If there already is an initial accumulator value\n",
    "                    \n",
    "                    # Create a variable containing the initial accumulator value everywhere\n",
    "                    # Add it to EM collection\n",
    "                    accum = tf.Variable(tf.ones_like(node.variable,\n",
    "                                                     dtype=conf.dtype) *\n",
    "                                        self._initial_accum_value,\n",
    "                                        dtype=conf.dtype,\n",
    "                                        collections=['em_accumulators'])\n",
    "                    \n",
    "                else:\n",
    "                    # Otherwise, use zero as accumulator init\n",
    "                    accum = tf.Variable(tf.zeros_like(node.variable,\n",
    "                                                      dtype=conf.dtype),\n",
    "                                        dtype=conf.dtype,\n",
    "                                        collections=['em_accumulators'])\n",
    "                # Creates a named tuple of node, accum and TF scope\n",
    "                param_node = EMLearning.ParamNode(node=node, accum=accum,\n",
    "                                                  name_scope=scope)\n",
    "                self._param_nodes.append(param_node)\n",
    "\n",
    "    self._param_nodes = []\n",
    "    with tf.name_scope(self._name_scope):\n",
    "        # Start at root, applying fun at each position\n",
    "        traverse_graph(self._root, fun=fun)\n",
    "\n",
    "```\n",
    "\n",
    "The key thing is to add it to the `_param_nodes` list. So let's see what `traverse_graph` does:\n",
    "```python\n",
    "def traverse_graph(root, fun, skip_params=False):\n",
    "    \"\"\"Runs ``fun`` on descendants of ``root`` (including ``root``) by\n",
    "    traversing the graph breadth-first until ``fun`` returns True.\n",
    "\n",
    "    Args:\n",
    "        root (Node): The root of the SPN graph.\n",
    "        fun (function): A function ``fun(node)`` executed once for every node of\n",
    "                        the graph. It should return ``True`` if traversing\n",
    "                        should be stopped.\n",
    "        skip_params (bool): If ``True``, the param nodes will not be traversed.\n",
    "\n",
    "    Returns:\n",
    "        Node: Returns the last traversed node (the one for which ``fun``\n",
    "        returned True) or ``None`` if ``fun`` never returned ``True``.\n",
    "    \"\"\"\n",
    "    visited_nodes = set()  # Set of visited nodes\n",
    "    queue = deque()\n",
    "    queue.append(root)\n",
    "\n",
    "    \"\"\" \n",
    "    In the example we see here, we eventually return None, \n",
    "    so we don't have a case where fun returns True.\n",
    "    \"\"\"\n",
    "    while queue:\n",
    "        next_node = queue.popleft()\n",
    "        if next_node not in visited_nodes:\n",
    "            if fun(next_node):\n",
    "                return next_node\n",
    "            visited_nodes.add(next_node)\n",
    "            # OpNode?: enqueue inputs\n",
    "            if next_node.is_op:\n",
    "                \"\"\" makes sure fun() is applied to these. Optionally ignores param Node \"\"\"\n",
    "                for i in next_node.inputs:\n",
    "                    if (i and  # Input not empty\n",
    "                            not (skip_params and i.is_param)):\n",
    "                        queue.append(i.node)\n",
    "\n",
    "    return None\n",
    "```\n",
    "\n",
    "Then, we use `accumulate_updates` to build the TF graph that makes the EM updates. This is defined in the `EMLearning` class:\n",
    "```python\n",
    "def accumulate_updates(self):\n",
    "    # Generate path if not yet generated\n",
    "    if not self._mpe_path.counts:\n",
    "        self._mpe_path.get_mpe_path(self._root)\n",
    "\n",
    "    # Generate all accumulate operations\n",
    "    with tf.name_scope(self._name_scope):\n",
    "        assign_ops = []\n",
    "        # For each of the parameter nodes that we collected in accumulator creation\n",
    "        for pn in self._param_nodes:\n",
    "            with tf.name_scope(pn.name_scope):\n",
    "                # Get count tensor corresponding to this node\n",
    "                counts = self._mpe_path.counts[pn.node]\n",
    "                # Compute the update value using the counts\n",
    "                update_value = pn.node._compute_hard_em_update(counts)\n",
    "                # Assign this EM value to the accumulator \n",
    "                op = tf.assign_add(pn.accum, update_value)\n",
    "                assign_ops.append(op)\n",
    "        return tf.group(*assign_ops, name=\"accumulate_updates\")\n",
    "```\n",
    "Interesting to know is the `_compute_hard_em_update` function. It is trivial:\n",
    "```python\n",
    "def _compute_hard_em_update(self, counts):\n",
    "    # Summing over 0th axis, counting the occurences of this node\n",
    "    return tf.reduce_sum(counts, axis=0)\n",
    "```\n",
    "More sophisticated is the function that determines the path:\n",
    "```python\n",
    "def get_mpe_path(self, root):\n",
    "    \"\"\"Assemble TF operations computing the branch counts for the MPE\n",
    "    downward path through the SPN rooted in ``root``.\n",
    "\n",
    "    Args:\n",
    "        root (Node): The root node of the SPN graph.\n",
    "    \"\"\"\n",
    "    def down_fun(node, parent_vals):\n",
    "        # Sum up all parent vals\n",
    "        if len(parent_vals) > 1:\n",
    "            summed = tf.add_n(parent_vals, name=node.name + \"_add\")\n",
    "        else:\n",
    "            summed = parent_vals[0]\n",
    "        self._counts[node] = summed # For root, this will be just be ones\n",
    "        if node.is_op:\n",
    "            # Compute for inputs\n",
    "            with tf.name_scope(node.name):\n",
    "                if self._log:\n",
    "                    return node._compute_log_mpe_path(\n",
    "                        summed, *[self._value.values[i.node]\n",
    "                                  if i else None\n",
    "                                  for i in node.inputs],\n",
    "                        add_random=self._add_random,\n",
    "                        use_unweighted=self._use_unweighted)\n",
    "                else:\n",
    "                    return node._compute_mpe_path(\n",
    "                        summed, *[self._value.values[i.node]\n",
    "                                  if i else None\n",
    "                                  for i in node.inputs],\n",
    "                        add_random=self._add_random,\n",
    "                        use_unweighted=self._use_unweighted)\n",
    "\n",
    "    # Generate values if not yet generated\n",
    "    if not self._value.values:\n",
    "        self._value.get_value(root)\n",
    "\n",
    "    with tf.name_scope(\"MPEPath\"):\n",
    "        # Compute the tensor to feed to the root node\n",
    "        # Basically sets input of root to ones\n",
    "        graph_input = tf.ones_like(self._value.values[root])\n",
    "\n",
    "        # Traverse the graph computing counts\n",
    "        self._counts = {}\n",
    "        compute_graph_up_down(root, down_fun=down_fun, graph_input=graph_input)\n",
    "```\n",
    "So this constructs the upward pass and the downward pass using `down_fun`. The downward function applies `_compute_log_mpe_path` to all of the nodes on the downward pass.\n",
    "\n",
    "```python\n",
    "def compute_graph_up_down(root, down_fun, graph_input, up_fun=None,\n",
    "                          up_values=None, down_values=None):\n",
    "    \"\"\"Computes a values for every node in the graph moving first up and then down\n",
    "    the graph. When moving up, it behaves exactly as :meth:`compute_graph_up`.\n",
    "    When moving down it computes values for each input of a node based on\n",
    "    values produced for inputs of parent nodes connected to this node. For this,\n",
    "    it traverses the graph breadth-first from the ``root`` node to the leaf nodes.\n",
    "\n",
    "    Args:\n",
    "        root (Node): The root of the SPN graph.\n",
    "        down_fun (function): A function ``down_fun(node, parent_vals)``\n",
    "            producing values for each input of the ``node``. The argument\n",
    "            ``parent_vals`` is a list containing the values obtained for each\n",
    "            parent node input connected to this node.\n",
    "        graph_input: The value passed as a single parent value to the function\n",
    "            computing the values for the root node or a function which computes\n",
    "            that value.\n",
    "        up_fun (function): A function ``up_fun(node, *args)`` producing a\n",
    "            certain value for the ``node``. For an op node, it will have\n",
    "            additional arguments with values produced for the input nodes of\n",
    "            ``node``. The arguments can be ``None`` if the input was empty.\n",
    "        up_values (dict): A dictionary indexed by ``node`` in which values\n",
    "            computed for each node during the upward pass will be stored. Can\n",
    "            be set to ``None``.\n",
    "        down_values (dict): A dictionary indexed by ``node`` in which values\n",
    "            computed for each input of a node during the downward pass will be\n",
    "            stored. Can be set to ``None``.\n",
    "    \"\"\"\n",
    "    if down_values is None:  # Dictionary of computed values indexed by node\n",
    "        down_values = {}\n",
    "    queue = deque()  # Queue of nodes with computed values, but unprocessed inputs\n",
    "    parents = defaultdict(list)  # Awesome, didn't know this trick\n",
    "\n",
    "    def up_fun_parents(node, *args):\n",
    "        \"\"\"Run up_fun and for each node find parent node inputs having the node\n",
    "        connected.\"\"\"\n",
    "        # For each input, add the node and input number as relevant parent node\n",
    "        # input to the connected node\n",
    "        if node.is_op:\n",
    "            for nr, inpt in enumerate(node.inputs):\n",
    "                if inpt:\n",
    "                    parents[inpt.node].append((node, nr))\n",
    "        # Run up_fun\n",
    "        if up_fun is not None:\n",
    "            return up_fun(node, *args)\n",
    "\n",
    "    # Traverse up\n",
    "    # up_values is none in this case, merely going up the graph while applying up_fun_parents\n",
    "    compute_graph_up(root, val_fun=up_fun_parents, all_values=up_values)\n",
    "\n",
    "    # Add root node\n",
    "    if callable(graph_input):\n",
    "        graph_input = graph_input()\n",
    "    down_values[root] = down_fun(root, [graph_input])\n",
    "    if root.is_op:\n",
    "        queue.append(root)\n",
    "\n",
    "    # Traverse down\n",
    "    while queue:\n",
    "        next_node = queue.popleft()\n",
    "        children = set(i.node for i in next_node.inputs if i)\n",
    "        for child in children:\n",
    "            if child not in down_values:  # Not computed yet\n",
    "                # Get all parent_vals\n",
    "                parent_vals = []\n",
    "                try:\n",
    "                    for parent_node, parent_input_nr in parents[child]:\n",
    "                        parent_vals.append(\n",
    "                            down_values[parent_node][parent_input_nr])\n",
    "                    # All parent values are available, compute value\n",
    "                    down_values[child] = down_fun(child, parent_vals)\n",
    "                    # Enqueue for further processing of children\n",
    "                    if child.is_op:\n",
    "                        queue.append(child)\n",
    "                except KeyError:\n",
    "                    # Not all parent values were available\n",
    "                    pass\n",
    "```\n",
    "\n",
    "Let's see what `_compute_log_mpe_path` does for sum nodes:\n",
    "```python\n",
    "def _compute_log_mpe_path(self, counts, weight_value, ivs_value, *value_values,\n",
    "                          add_random=None, use_unweighted=False):\n",
    "    # Get weighted, IV selected values\n",
    "    weight_value, ivs_value, values = self._compute_value_common(\n",
    "        weight_value, ivs_value, *value_values)\n",
    "    values_selected = values + ivs_value if self._ivs else values\n",
    "\n",
    "    # WARN USING UNWEIGHTED VALUE\n",
    "    if not use_unweighted or any(v.node.is_var for v in self._values):\n",
    "        values_weighted = values_selected + weight_value \"\"\" multiplication <=> addition in log space \"\"\"\n",
    "    else:\n",
    "        values_weighted = values_selected\n",
    "\n",
    "    # / USING UNWEIGHTED VALUE\n",
    "\n",
    "    # WARN ADDING RANDOM NUMBERS\n",
    "    if add_random is not None:\n",
    "        values_weighted = tf.add(values_weighted, tf.random_uniform(\n",
    "            shape=(tf.shape(values_weighted)[0],\n",
    "                   int(values_weighted.get_shape()[1])),\n",
    "            minval=0, maxval=add_random,\n",
    "            dtype=conf.dtype))\n",
    "    # /ADDING RANDOM NUMBERS\n",
    "\n",
    "    return self._compute_mpe_path_common(\n",
    "        values_weighted, counts, weight_value, ivs_value, *value_values)\n",
    "\n",
    "```\n",
    "\n",
    "Which refers to `_compute_mpe_path_common`:\n",
    "```python\n",
    "\n",
    "def _compute_mpe_path_common(self, values_weighted, counts, weight_value,\n",
    "                             ivs_value, *value_values):\n",
    "    # Propagate the counts to the max value\n",
    "    # Get indices of max elements\n",
    "    max_indices = tf.argmax(values_weighted, dimension=1)\n",
    "    # Create one_hot vector with max indices set to 1, multiplied with the counts tensor \n",
    "    max_counts = tf.one_hot(max_indices,\n",
    "                            values_weighted.get_shape()[1]) * counts\n",
    "    # Split the counts to value inputs\n",
    "    \"\"\" Apparently, the first two elements of self.inputs are different \"\"\"\n",
    "    _, _, *value_sizes = self.get_input_sizes(None, None, *value_values)\n",
    "    # Splits the tensor so that each of the elements can be given to the children\n",
    "    # Of course, this means that we split along the 1st axis\n",
    "    max_counts_split = utils.split_maybe(max_counts, value_sizes, 1)\n",
    "    # Use the custom scatter op\n",
    "    return self._scatter_to_input_tensors(\n",
    "        (max_counts, weight_value),  # Weights\n",
    "        (max_counts, ivs_value),  # IVs\n",
    "        *[(t, v) for t, v in zip(max_counts_split, value_values)])  # Values\n",
    "```\n",
    "Which refers to `_scatter_to_input_tensors`:\n",
    "\n",
    "```python\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Likelihood: -1.2939459\n",
      "Avg. Likelihood: -1.2843871\n",
      "Avg. Likelihood: -1.2565484\n",
      "Avg. Likelihood: -1.2453744\n",
      "Avg. Likelihood: -1.2396214\n",
      "Avg. Likelihood: -1.2361908\n",
      "Avg. Likelihood: -1.23394\n",
      "Avg. Likelihood: -1.2323612\n",
      "Avg. Likelihood: -1.2311978\n",
      "Avg. Likelihood: -1.2303077\n",
      "Avg. Likelihood: -1.2296064\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "with spn.session() as (sess, run):\n",
    "    sess.run(init_weights)\n",
    "    sess.run(init_learning)\n",
    "    while run():\n",
    "        likelihood_arr, _ = sess.run([likelihood, accumulate_updates],\n",
    "                                  feed_dict={iv_x:iv_x_arr, iv_y:iv_y_arr})\n",
    "        print(\"Avg. Likelihood: %s\" % (likelihood_arr))\n",
    "        sess.run(update_spn)\n",
    "        epoch+=1\n",
    "        if epoch > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1300px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.661075675226929&quot;).pbtxt = 'node {\\n  name: &quot;iv_x/Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;iv_y/Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/max&quot;\\n  input: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/RandomUniform&quot;\\n  input: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/mul&quot;\\n  input: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/normalize_tensor/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/normalize_tensor/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform&quot;\\n  input: &quot;Weights/sum_22_Weights/normalize_tensor/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/normalize_tensor/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Weights/sum_22_Weights/broadcast_value/random_uniform&quot;\\n  input: &quot;Weights/sum_22_Weights/normalize_tensor/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Weights/sum_22_Weights/Variable&quot;\\n  input: &quot;Weights/sum_22_Weights/normalize_tensor/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_22_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_22_Weights/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Weights/sum_22_Weights/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_22_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/max&quot;\\n  input: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/RandomUniform&quot;\\n  input: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/mul&quot;\\n  input: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/normalize_tensor/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/normalize_tensor/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform&quot;\\n  input: &quot;Weights/sum_12_Weights/normalize_tensor/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/normalize_tensor/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Weights/sum_12_Weights/broadcast_value/random_uniform&quot;\\n  input: &quot;Weights/sum_12_Weights/normalize_tensor/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Weights/sum_12_Weights/Variable&quot;\\n  input: &quot;Weights/sum_12_Weights/normalize_tensor/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_12_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_12_Weights/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Weights/sum_12_Weights/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_12_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/max&quot;\\n  input: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/RandomUniform&quot;\\n  input: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/mul&quot;\\n  input: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/normalize_tensor/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/normalize_tensor/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform&quot;\\n  input: &quot;Weights/sum_11_Weights/normalize_tensor/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/normalize_tensor/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Weights/sum_11_Weights/broadcast_value/random_uniform&quot;\\n  input: &quot;Weights/sum_11_Weights/normalize_tensor/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Weights/sum_11_Weights/Variable&quot;\\n  input: &quot;Weights/sum_11_Weights/normalize_tensor/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_11_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_11_Weights/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Weights/sum_11_Weights/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_11_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/max&quot;\\n  input: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/RandomUniform&quot;\\n  input: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/mul&quot;\\n  input: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/normalize_tensor/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/normalize_tensor/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform&quot;\\n  input: &quot;Weights/sum_21_Weights/normalize_tensor/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/normalize_tensor/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Weights/sum_21_Weights/broadcast_value/random_uniform&quot;\\n  input: &quot;Weights/sum_21_Weights/normalize_tensor/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Weights/sum_21_Weights/Variable&quot;\\n  input: &quot;Weights/sum_21_Weights/normalize_tensor/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_21_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/sum_21_Weights/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Weights/sum_21_Weights/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_21_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/broadcast_value/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/broadcast_value/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/broadcast_value/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/broadcast_value/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;Weights/root_Weights/broadcast_value/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/broadcast_value/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Weights/root_Weights/broadcast_value/random_uniform/max&quot;\\n  input: &quot;Weights/root_Weights/broadcast_value/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/broadcast_value/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Weights/root_Weights/broadcast_value/random_uniform/RandomUniform&quot;\\n  input: &quot;Weights/root_Weights/broadcast_value/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/broadcast_value/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Weights/root_Weights/broadcast_value/random_uniform/mul&quot;\\n  input: &quot;Weights/root_Weights/broadcast_value/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/normalize_tensor/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/normalize_tensor/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Weights/root_Weights/broadcast_value/random_uniform&quot;\\n  input: &quot;Weights/root_Weights/normalize_tensor/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/normalize_tensor/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Weights/root_Weights/broadcast_value/random_uniform&quot;\\n  input: &quot;Weights/root_Weights/normalize_tensor/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Weights/root_Weights/Variable&quot;\\n  input: &quot;Weights/root_Weights/normalize_tensor/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/root_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Weights/root_Weights/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Weights/root_Weights/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/root_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;InitializeWeights/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Weights/root_Weights/Variable/Assign&quot;\\n  input: &quot;^Weights/sum_11_Weights/Variable/Assign&quot;\\n  input: &quot;^Weights/sum_21_Weights/Variable/Assign&quot;\\n  input: &quot;^Weights/sum_22_Weights/Variable/Assign&quot;\\n  input: &quot;^Weights/sum_12_Weights/Variable/Assign&quot;\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/ones_like/Shape&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/mul/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/ones_like&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/mul/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/root_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/root_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/ones_like/Shape&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/mul/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/ones_like&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/mul/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_11_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_11_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/ones_like/Shape&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/mul/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/ones_like&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/mul/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_21_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_21_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/ones_like/Shape&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/mul/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/ones_like&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/mul/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_22_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_22_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/ones_like/Shape&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/mul/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/ones_like&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/mul/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_12_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_12_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/reset_accumulators&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^EMLearning/Weights/root_Weights/Variable/Assign&quot;\\n  input: &quot;^EMLearning/Weights/sum_11_Weights/Variable/Assign&quot;\\n  input: &quot;^EMLearning/Weights/sum_21_Weights/Variable/Assign&quot;\\n  input: &quot;^EMLearning/Weights/sum_22_Weights/Variable/Assign&quot;\\n  input: &quot;^EMLearning/Weights/sum_12_Weights/Variable/Assign&quot;\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;iv_x/Placeholder&quot;\\n  input: &quot;LogValue/iv_x/one_hot/depth&quot;\\n  input: &quot;LogValue/iv_x/one_hot/on_value&quot;\\n  input: &quot;LogValue/iv_x/one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/Less/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;iv_x/Placeholder&quot;\\n  input: &quot;LogValue/iv_x/Less/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;LogValue/iv_x/Less&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;LogValue/iv_x/Cast&quot;\\n  input: &quot;LogValue/iv_x/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/iv_x/one_hot&quot;\\n  input: &quot;LogValue/iv_x/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\004\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;LogValue/iv_x/Add&quot;\\n  input: &quot;LogValue/iv_x/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_x/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;LogValue/iv_x/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/Weights/sum_22_Weights/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;Weights/sum_22_Weights/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\002\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  op: &quot;GatherColumns&quot;\\n  input: &quot;LogValue/iv_x/Log&quot;\\n  input: &quot;LogValue/sum_22/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/sum_22/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  input: &quot;LogValue/Weights/sum_22_Weights/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Max/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;LogValue/sum_22/add&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Max/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;LogValue/sum_22/add&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Max&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Exp&quot;\\n  op: &quot;Exp&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Exp&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Max&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Max&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Shape&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_22/reduce_log_sum/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Equal&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Fill&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/Weights/sum_12_Weights/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;Weights/sum_12_Weights/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  op: &quot;GatherColumns&quot;\\n  input: &quot;LogValue/iv_x/Log&quot;\\n  input: &quot;LogValue/sum_12/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/sum_12/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  input: &quot;LogValue/Weights/sum_12_Weights/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Max/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;LogValue/sum_12/add&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Max/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;LogValue/sum_12/add&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Max&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Exp&quot;\\n  op: &quot;Exp&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Exp&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Max&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Max&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Shape&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_12/reduce_log_sum/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Equal&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Fill&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_3/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_3/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LogValue/sum_12/reduce_log_sum/Select&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Select&quot;\\n  input: &quot;LogValue/prod_3/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_3/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_3/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;LogValue/prod_3/concat&quot;\\n  input: &quot;LogValue/prod_3/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/Weights/sum_11_Weights/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;Weights/sum_11_Weights/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  op: &quot;GatherColumns&quot;\\n  input: &quot;LogValue/iv_x/Log&quot;\\n  input: &quot;LogValue/sum_11/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/sum_11/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  input: &quot;LogValue/Weights/sum_11_Weights/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Max/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;LogValue/sum_11/add&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Max/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;LogValue/sum_11/add&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Max&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Exp&quot;\\n  op: &quot;Exp&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Exp&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Max&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Max&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Shape&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_11/reduce_log_sum/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Equal&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Fill&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_2/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_2/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Select&quot;\\n  input: &quot;LogValue/sum_22/reduce_log_sum/Select&quot;\\n  input: &quot;LogValue/prod_2/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_2/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_2/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;LogValue/prod_2/concat&quot;\\n  input: &quot;LogValue/prod_2/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/Weights/sum_21_Weights/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;Weights/sum_21_Weights/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\002\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  op: &quot;GatherColumns&quot;\\n  input: &quot;LogValue/iv_x/Log&quot;\\n  input: &quot;LogValue/sum_21/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/sum_21/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  input: &quot;LogValue/Weights/sum_21_Weights/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Max/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;LogValue/sum_21/add&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Max/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;LogValue/sum_21/add&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Max&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Exp&quot;\\n  op: &quot;Exp&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Exp&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Max&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Max&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Shape&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/sum_21/reduce_log_sum/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Equal&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Fill&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_1/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_1/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LogValue/sum_11/reduce_log_sum/Select&quot;\\n  input: &quot;LogValue/sum_21/reduce_log_sum/Select&quot;\\n  input: &quot;LogValue/prod_1/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_1/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/prod_1/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;LogValue/prod_1/concat&quot;\\n  input: &quot;LogValue/prod_1/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;iv_y/Placeholder&quot;\\n  input: &quot;LogValue/iv_y/one_hot/depth&quot;\\n  input: &quot;LogValue/iv_y/one_hot/on_value&quot;\\n  input: &quot;LogValue/iv_y/one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/Less/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;iv_y/Placeholder&quot;\\n  input: &quot;LogValue/iv_y/Less/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;LogValue/iv_y/Less&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;LogValue/iv_y/Cast&quot;\\n  input: &quot;LogValue/iv_y/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/iv_y/one_hot&quot;\\n  input: &quot;LogValue/iv_y/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;LogValue/iv_y/Add&quot;\\n  input: &quot;LogValue/iv_y/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/iv_y/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;LogValue/iv_y/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/Weights/root_Weights/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;Weights/root_Weights/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LogValue/prod_1/Sum&quot;\\n  input: &quot;LogValue/prod_2/Sum&quot;\\n  input: &quot;LogValue/prod_3/Sum&quot;\\n  input: &quot;LogValue/root/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/root/concat&quot;\\n  input: &quot;LogValue/iv_y/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/root/add&quot;\\n  input: &quot;LogValue/Weights/root_Weights/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Max/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;LogValue/root/add_1&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Max/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;LogValue/root/add_1&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Max&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Exp&quot;\\n  op: &quot;Exp&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Exp&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Max&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Max&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Shape&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LogValue/root/reduce_log_sum/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Equal&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Fill&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/ones_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;MPEPath/ones_like/Shape&quot;\\n  input: &quot;MPEPath/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LogValue/prod_1/Sum&quot;\\n  input: &quot;LogValue/prod_2/Sum&quot;\\n  input: &quot;LogValue/prod_3/Sum&quot;\\n  input: &quot;MPEPath/root/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MPEPath/root/concat&quot;\\n  input: &quot;LogValue/iv_y/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MPEPath/root/add&quot;\\n  input: &quot;LogValue/Weights/root_Weights/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;MPEPath/root/add_1&quot;\\n  input: &quot;MPEPath/root/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;MPEPath/root/ArgMax&quot;\\n  input: &quot;MPEPath/root/one_hot/depth&quot;\\n  input: &quot;MPEPath/root/one_hot/on_value&quot;\\n  input: &quot;MPEPath/root/one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;MPEPath/root/one_hot&quot;\\n  input: &quot;MPEPath/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/root/split&quot;\\n  op: &quot;SplitV&quot;\\n  input: &quot;MPEPath/root/mul&quot;\\n  input: &quot;MPEPath/root/Const&quot;\\n  input: &quot;MPEPath/root/split/split_dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  op: &quot;GatherColumns&quot;\\n  input: &quot;LogValue/iv_x/Log&quot;\\n  input: &quot;MPEPath/sum_12/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MPEPath/sum_12/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  input: &quot;LogValue/Weights/sum_12_Weights/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;MPEPath/sum_12/add&quot;\\n  input: &quot;MPEPath/sum_12/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;MPEPath/sum_12/ArgMax&quot;\\n  input: &quot;MPEPath/sum_12/one_hot/depth&quot;\\n  input: &quot;MPEPath/sum_12/one_hot/on_value&quot;\\n  input: &quot;MPEPath/sum_12/one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;MPEPath/sum_12/one_hot&quot;\\n  input: &quot;MPEPath/root/split:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/scatter_to_input_tensors/scatter_cols/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/scatter_to_input_tensors/scatter_cols/ScatterColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_12/scatter_to_input_tensors/scatter_cols/ScatterColumns&quot;\\n  op: &quot;ScatterColumns&quot;\\n  input: &quot;MPEPath/sum_12/mul&quot;\\n  input: &quot;MPEPath/sum_12/scatter_to_input_tensors/scatter_cols/ScatterColumns/indices&quot;\\n  input: &quot;MPEPath/sum_12/scatter_to_input_tensors/scatter_cols/Const&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_out_col&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22_add&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;MPEPath/root/split:2&quot;\\n  input: &quot;MPEPath/root/split:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\002\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  op: &quot;GatherColumns&quot;\\n  input: &quot;LogValue/iv_x/Log&quot;\\n  input: &quot;MPEPath/sum_22/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MPEPath/sum_22/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  input: &quot;LogValue/Weights/sum_22_Weights/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;MPEPath/sum_22/add&quot;\\n  input: &quot;MPEPath/sum_22/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;MPEPath/sum_22/ArgMax&quot;\\n  input: &quot;MPEPath/sum_22/one_hot/depth&quot;\\n  input: &quot;MPEPath/sum_22/one_hot/on_value&quot;\\n  input: &quot;MPEPath/sum_22/one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;MPEPath/sum_22/one_hot&quot;\\n  input: &quot;MPEPath/sum_22_add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/scatter_to_input_tensors/scatter_cols/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/scatter_to_input_tensors/scatter_cols/ScatterColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\002\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_22/scatter_to_input_tensors/scatter_cols/ScatterColumns&quot;\\n  op: &quot;ScatterColumns&quot;\\n  input: &quot;MPEPath/sum_22/mul&quot;\\n  input: &quot;MPEPath/sum_22/scatter_to_input_tensors/scatter_cols/ScatterColumns/indices&quot;\\n  input: &quot;MPEPath/sum_22/scatter_to_input_tensors/scatter_cols/Const&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_out_col&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11_add&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;MPEPath/root/split:1&quot;\\n  input: &quot;MPEPath/root/split&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  op: &quot;GatherColumns&quot;\\n  input: &quot;LogValue/iv_x/Log&quot;\\n  input: &quot;MPEPath/sum_11/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MPEPath/sum_11/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  input: &quot;LogValue/Weights/sum_11_Weights/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;MPEPath/sum_11/add&quot;\\n  input: &quot;MPEPath/sum_11/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;MPEPath/sum_11/ArgMax&quot;\\n  input: &quot;MPEPath/sum_11/one_hot/depth&quot;\\n  input: &quot;MPEPath/sum_11/one_hot/on_value&quot;\\n  input: &quot;MPEPath/sum_11/one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;MPEPath/sum_11/one_hot&quot;\\n  input: &quot;MPEPath/sum_11_add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/scatter_to_input_tensors/scatter_cols/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/scatter_to_input_tensors/scatter_cols/ScatterColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_11/scatter_to_input_tensors/scatter_cols/ScatterColumns&quot;\\n  op: &quot;ScatterColumns&quot;\\n  input: &quot;MPEPath/sum_11/mul&quot;\\n  input: &quot;MPEPath/sum_11/scatter_to_input_tensors/scatter_cols/ScatterColumns/indices&quot;\\n  input: &quot;MPEPath/sum_11/scatter_to_input_tensors/scatter_cols/Const&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_out_col&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\002\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  op: &quot;GatherColumns&quot;\\n  input: &quot;LogValue/iv_x/Log&quot;\\n  input: &quot;MPEPath/sum_21/gather_input_tensors/gather_cols/GatherColumns/indices&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MPEPath/sum_21/gather_input_tensors/gather_cols/GatherColumns&quot;\\n  input: &quot;LogValue/Weights/sum_21_Weights/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;MPEPath/sum_21/add&quot;\\n  input: &quot;MPEPath/sum_21/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;MPEPath/sum_21/ArgMax&quot;\\n  input: &quot;MPEPath/sum_21/one_hot/depth&quot;\\n  input: &quot;MPEPath/sum_21/one_hot/on_value&quot;\\n  input: &quot;MPEPath/sum_21/one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;MPEPath/sum_21/one_hot&quot;\\n  input: &quot;MPEPath/root/split&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/scatter_to_input_tensors/scatter_cols/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/scatter_to_input_tensors/scatter_cols/ScatterColumns/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\002\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/sum_21/scatter_to_input_tensors/scatter_cols/ScatterColumns&quot;\\n  op: &quot;ScatterColumns&quot;\\n  input: &quot;MPEPath/sum_21/mul&quot;\\n  input: &quot;MPEPath/sum_21/scatter_to_input_tensors/scatter_cols/ScatterColumns/indices&quot;\\n  input: &quot;MPEPath/sum_21/scatter_to_input_tensors/scatter_cols/Const&quot;\\n  attr {\\n    key: &quot;IndT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_out_col&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MPEPath/iv_x_add&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;MPEPath/sum_22/scatter_to_input_tensors/scatter_cols/ScatterColumns&quot;\\n  input: &quot;MPEPath/sum_12/scatter_to_input_tensors/scatter_cols/ScatterColumns&quot;\\n  input: &quot;MPEPath/sum_11/scatter_to_input_tensors/scatter_cols/ScatterColumns&quot;\\n  input: &quot;MPEPath/sum_21/scatter_to_input_tensors/scatter_cols/ScatterColumns&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;MPEPath/root/mul&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/AssignAdd&quot;\\n  op: &quot;AssignAdd&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/root_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;MPEPath/sum_11/mul&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/AssignAdd&quot;\\n  op: &quot;AssignAdd&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_11_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;MPEPath/sum_21/mul&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/AssignAdd&quot;\\n  op: &quot;AssignAdd&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_21_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;MPEPath/sum_22/mul&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/AssignAdd&quot;\\n  op: &quot;AssignAdd&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_22_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;MPEPath/sum_12/mul&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/AssignAdd&quot;\\n  op: &quot;AssignAdd&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@EMLearning/Weights/sum_12_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/accumulate_updates&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^EMLearning/Weights/root_Weights/AssignAdd&quot;\\n  input: &quot;^EMLearning/Weights/sum_11_Weights/AssignAdd&quot;\\n  input: &quot;^EMLearning/Weights/sum_21_Weights/AssignAdd&quot;\\n  input: &quot;^EMLearning/Weights/sum_22_Weights/AssignAdd&quot;\\n  input: &quot;^EMLearning/Weights/sum_12_Weights/AssignAdd&quot;\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/normalize_tensor/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/normalize_tensor/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/Variable/read&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/normalize_tensor/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/normalize_tensor/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/Variable/read&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/normalize_tensor/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/root_Weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Weights/root_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/root_Weights/normalize_tensor/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/root_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/normalize_tensor/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/normalize_tensor/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/Variable/read&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/normalize_tensor/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/normalize_tensor/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/Variable/read&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/normalize_tensor/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_11_Weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Weights/sum_11_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_11_Weights/normalize_tensor/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_11_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/normalize_tensor/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/normalize_tensor/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/Variable/read&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/normalize_tensor/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/normalize_tensor/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/Variable/read&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/normalize_tensor/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_21_Weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Weights/sum_21_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_21_Weights/normalize_tensor/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_21_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/normalize_tensor/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/normalize_tensor/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/Variable/read&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/normalize_tensor/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/normalize_tensor/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/Variable/read&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/normalize_tensor/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_22_Weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Weights/sum_22_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_22_Weights/normalize_tensor/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_22_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/normalize_tensor/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/normalize_tensor/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/Variable/read&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/normalize_tensor/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/normalize_tensor/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/Variable/read&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/normalize_tensor/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/Weights/sum_12_Weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Weights/sum_12_Weights/Variable&quot;\\n  input: &quot;EMLearning/Weights/sum_12_Weights/normalize_tensor/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Weights/sum_12_Weights/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;EMLearning/update_spn&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^EMLearning/Weights/root_Weights/Assign&quot;\\n  input: &quot;^EMLearning/Weights/sum_11_Weights/Assign&quot;\\n  input: &quot;^EMLearning/Weights/sum_21_Weights/Assign&quot;\\n  input: &quot;^EMLearning/Weights/sum_22_Weights/Assign&quot;\\n  input: &quot;^EMLearning/Weights/sum_12_Weights/Assign&quot;\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;LogValue/root/reduce_log_sum/Select&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n}\\nnode {\\n  name: &quot;init_1&quot;\\n  op: &quot;NoOp&quot;\\n}\\nnode {\\n  name: &quot;group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^init&quot;\\n  input: &quot;^init_1&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot;\n",
       "              onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.661075675226929&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spn.display_tf_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what do we get when we run `spn.session()`? A TF session and a `run` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shape [-1,2] has negative dimensions\n\t [[Node: iv_x/Placeholder = Placeholder[dtype=DT_INT32, shape=[?,2], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'iv_x/Placeholder', defined at:\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/jos/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/jos/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/jos/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jos/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/jos/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/jos/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/jos/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-cf96ec3a9083>\", line 1, in <module>\n    iv_x = spn.IVs(num_vars=2, num_vals=2, name=\"iv_x\")\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/libspn/graph/ivs.py\", line 37, in __init__\n    super().__init__(feed, name)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/libspn/graph/node.py\", line 757, in __init__\n    super().__init__(InferenceType.MARGINAL, name)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/libspn/graph/node.py\", line 207, in __init__\n    self._create()\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/libspn/graph/node.py\", line 786, in _create\n    self._placeholder = self._create_placeholder()\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/libspn/graph/ivs.py\", line 68, in _create_placeholder\n    return tf.placeholder(tf.int32, [None, self._num_vars])\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,2] has negative dimensions\n\t [[Node: iv_x/Placeholder = Placeholder[dtype=DT_INT32, shape=[?,2], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libspn/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape [-1,2] has negative dimensions\n\t [[Node: iv_x/Placeholder = Placeholder[dtype=DT_INT32, shape=[?,2], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-68caea79fe6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mlikelihoods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulate_updates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Avg. Likelihood: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mavg_likelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_spn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape [-1,2] has negative dimensions\n\t [[Node: iv_x/Placeholder = Placeholder[dtype=DT_INT32, shape=[?,2], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'iv_x/Placeholder', defined at:\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/jos/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/jos/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/jos/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jos/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/jos/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/jos/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/jos/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jos/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-cf96ec3a9083>\", line 1, in <module>\n    iv_x = spn.IVs(num_vars=2, num_vals=2, name=\"iv_x\")\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/libspn/graph/ivs.py\", line 37, in __init__\n    super().__init__(feed, name)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/libspn/graph/node.py\", line 757, in __init__\n    super().__init__(InferenceType.MARGINAL, name)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/libspn/graph/node.py\", line 207, in __init__\n    self._create()\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/libspn/graph/node.py\", line 786, in _create\n    self._placeholder = self._create_placeholder()\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/libspn/graph/ivs.py\", line 68, in _create_placeholder\n    return tf.placeholder(tf.int32, [None, self._num_vars])\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/jos/anaconda3/envs/libspn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,2] has negative dimensions\n\t [[Node: iv_x/Placeholder = Placeholder[dtype=DT_INT32, shape=[?,2], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with spn.session() as (sess, run):\n",
    "    sess.run(init_weights)\n",
    "    sess.run(init_learning)\n",
    "    try:\n",
    "        while run():\n",
    "            likelihoods, _ =  sess.run([likelihood, accumulate_updates])\n",
    "            print(\"Avg. Likelihood: %s\" % (avg_likelihood))\n",
    "            sess.run(update_spn)\n",
    "            \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"TRAINING DONE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
