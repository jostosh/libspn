{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import libspn as spn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Test Graph with Random Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iv_x = spn.IVs(num_vars=2, num_vals=2, name=\"iv_x\")\n",
    "sum_11 = spn.Sum((iv_x, [0,1]), name=\"sum_11\")\n",
    "sum_12 = spn.Sum((iv_x, [0,1]), name=\"sum_12\")\n",
    "sum_21 = spn.Sum((iv_x, [2,3]), name=\"sum_21\")\n",
    "sum_22 = spn.Sum((iv_x, [2,3]), name=\"sum_22\")\n",
    "prod_1 = spn.Product(sum_11, sum_21, name=\"prod_1\")\n",
    "prod_2 = spn.Product(sum_11, sum_22, name=\"prod_2\")\n",
    "prod_3 = spn.Product(sum_12, sum_22, name=\"prod_3\")\n",
    "root = spn.Sum(prod_1, prod_2, prod_3, name=\"root\")\n",
    "iv_y = root.generate_ivs(name=\"iv_y\")\n",
    "spn.generate_weights(root, initializer=tf.initializers.random_uniform(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the SPN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spn.display_spn_graph(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iv_x_arr=[[0,0],[0,0],[1,1],[1,1],[1,1],[0,1],[0,1],[0,1]]\n",
    "iv_y_arr=[[-1]] * len(iv_x_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Learning Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights = spn.initialize_weights(root)\n",
    "learning = spn.EMLearning(root, initial_accum_value=2)\n",
    "init_learning = learning.reset_accumulators()\n",
    "accumulate_updates = learning.accumulate_updates()\n",
    "update_spn = learning.update_spn()\n",
    "likelihood = tf.reduce_mean(learning.value.values[root])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "with spn.session() as (sess, run):\n",
    "    sess.run(init_weights)\n",
    "    sess.run(init_learning)\n",
    "    while run():\n",
    "        likelihood_arr, _ = sess.run([likelihood, accumulate_updates],\n",
    "                                  feed_dict={iv_x:iv_x_arr, iv_y:iv_y_arr})\n",
    "        print(\"Avg. Likelihood: %s\" % (likelihood_arr))\n",
    "        sess.run(update_spn)\n",
    "        epoch+=1\n",
    "        if epoch > 10:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
