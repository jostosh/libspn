{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def reduce_max(input_tensor,\n",
    "               axis=None,\n",
    "               keepdims=None,\n",
    "               name=None,\n",
    "               reduction_indices=None,\n",
    "               keep_dims=None):\n",
    "  \"\"\"Computes the maximum of elements across dimensions of a tensor.\n",
    "  Reduces `input_tensor` along the dimensions given in `axis`.\n",
    "  Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
    "  entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
    "  are retained with length 1.\n",
    "  If `axis` has no entries, all dimensions are reduced, and a\n",
    "  tensor with a single element is returned.\n",
    "  Args:\n",
    "    input_tensor: The tensor to reduce. Should have numeric type.\n",
    "    axis: The dimensions to reduce. If `None` (the default),\n",
    "      reduces all dimensions. Must be in the range\n",
    "      `[-rank(input_tensor), rank(input_tensor))`.\n",
    "    keepdims: If true, retains reduced dimensions with length 1.\n",
    "    name: A name for the operation (optional).\n",
    "    reduction_indices: The old (deprecated) name for axis.\n",
    "    keep_dims: Deprecated alias for `keepdims`.\n",
    "  Returns:\n",
    "    The reduced tensor.\n",
    "  @compatibility(numpy)\n",
    "  Equivalent to np.max\n",
    "  @end_compatibility\n",
    "  \"\"\"\n",
    "  keepdims = deprecation.deprecated_argument_lookup(\"keepdims\", keepdims,\n",
    "                                                    \"keep_dims\", keep_dims)\n",
    "  if keepdims is None:\n",
    "    keepdims = False\n",
    "  return _may_reduce_to_scalar(keepdims, axis, reduction_indices,\n",
    "                               gen_math_ops._max(\n",
    "                                   input_tensor,\n",
    "                                   _ReductionDims(input_tensor, axis,\n",
    "                                                  reduction_indices),\n",
    "                                   keepdims,\n",
    "                                   name=name))\n",
    "```\n",
    "\n",
    "C-code for Op def:\n",
    "\n",
    "```cpp\n",
    "REGISTER_OP(\"ArgMax\")\n",
    "    .Input(\"input: T\")\n",
    "    .Input(\"dimension: Tidx\")\n",
    "    .Output(\"output: output_type\")\n",
    "    .Attr(\"T: numbertype\")\n",
    "    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n",
    "    .Attr(\"output_type: {int32, int64} = DT_INT64\")\n",
    "    .SetShapeFn(ArgOpShape);\n",
    "```\n",
    "\n",
    "In tensorflow/tensorflow/core/kernels/argmax_op_gpu.cu.cc, we have:\n",
    "\n",
    "```cpp\n",
    "\n",
    "\n",
    "#if GOOGLE_CUDA\n",
    "\n",
    "#define EIGEN_USE_GPU\n",
    "\n",
    "#include \"tensorflow/core/framework/register_types.h\"\n",
    "#include \"tensorflow/core/kernels/argmax_op.h\"\n",
    "\n",
    "namespace tensorflow {\n",
    "\n",
    "typedef Eigen::GpuDevice GPUDevice;\n",
    "\n",
    "#define DEFINE_GPU_SPEC(T)                              \\\n",
    "  template struct functor::ArgMax<GPUDevice, T, int64>; \\\n",
    "  template struct functor::ArgMin<GPUDevice, T, int64>; \\\n",
    "  template struct functor::ArgMax<GPUDevice, T, int32>; \\\n",
    "  template struct functor::ArgMin<GPUDevice, T, int32>;\n",
    "\n",
    "TF_CALL_GPU_NUMBER_TYPES(DEFINE_GPU_SPEC);\n",
    "\n",
    "}  // end namespace tensorflow\n",
    "\n",
    "#endif  // GOOGLE_CUDA\n",
    "```\n",
    "\n",
    "## tensorflow/tensorflow/core/kernels/argmax_op.h\n",
    "\n",
    "```cpp\n",
    "\n",
    "#ifndef TENSORFLOW_KERNELS_ARGMAX_OP_H_\n",
    "#define TENSORFLOW_KERNELS_ARGMAX_OP_H_\n",
    "// Generator definition for ArgMaxOp, must be compilable by nvcc.\n",
    "\n",
    "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n",
    "#include \"tensorflow/core/framework/tensor_types.h\"\n",
    "#include \"tensorflow/core/platform/types.h\"\n",
    "\n",
    "namespace tensorflow {\n",
    "\n",
    "namespace functor {\n",
    "\n",
    "template <typename Device, typename T, typename Tout>\n",
    "struct ArgMax {\n",
    "#define DECLARE_COMPUTE_SPEC(Dims)                                             \\\n",
    "  EIGEN_ALWAYS_INLINE static void Reduce##Dims(                                \\\n",
    "      const Device& d, typename TTypes<T, Dims>::ConstTensor input,            \\\n",
    "      const int32 dimension, typename TTypes<Tout, Dims - 1>::Tensor output) { \\\n",
    "    output.device(d) = input.argmax(dimension).template cast<Tout>();          \\\n",
    "  }\n",
    "\n",
    "  DECLARE_COMPUTE_SPEC(1);\n",
    "  DECLARE_COMPUTE_SPEC(2);\n",
    "  DECLARE_COMPUTE_SPEC(3);\n",
    "  DECLARE_COMPUTE_SPEC(4);\n",
    "  DECLARE_COMPUTE_SPEC(5);\n",
    "\n",
    "#undef DECLARE_COMPUTE_SPEC\n",
    "};\n",
    "\n",
    "template <typename Device, typename T, typename Tout>\n",
    "struct ArgMin {\n",
    "#define DECLARE_COMPUTE_SPEC(Dims)                                             \\\n",
    "  EIGEN_ALWAYS_INLINE static void Reduce##Dims(                                \\\n",
    "      const Device& d, typename TTypes<T, Dims>::ConstTensor input,            \\\n",
    "      const int32 dimension, typename TTypes<Tout, Dims - 1>::Tensor output) { \\\n",
    "    output.device(d) = input.argmin(dimension).template cast<Tout>();          \\\n",
    "  }\n",
    "\n",
    "  DECLARE_COMPUTE_SPEC(1);\n",
    "  DECLARE_COMPUTE_SPEC(2);\n",
    "  DECLARE_COMPUTE_SPEC(3);\n",
    "  DECLARE_COMPUTE_SPEC(4);\n",
    "  DECLARE_COMPUTE_SPEC(5);\n",
    "\n",
    "#undef DECLARE_COMPUTE_SPEC\n",
    "};\n",
    "\n",
    "}  // namespace functor\n",
    "\n",
    "}  // namespace tensorflow\n",
    "```\n",
    "\n",
    "## tensorflow/tensorflow/core/kernels/argmax_op.cc\n",
    "```cpp\n",
    "#define EIGEN_USE_THREADS\n",
    "\n",
    "#if GOOGLE_CUDA\n",
    "#define EIGEN_USE_GPU\n",
    "#endif  // GOOGLE_CUDA\n",
    "\n",
    "#include \"tensorflow/core/kernels/argmax_op.h\"\n",
    "\n",
    "#include <memory>\n",
    "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n",
    "#include \"tensorflow/core/framework/op_kernel.h\"\n",
    "#include \"tensorflow/core/framework/register_types.h\"\n",
    "#include \"tensorflow/core/framework/tensor.h\"\n",
    "#include \"tensorflow/core/framework/tensor_shape.h\"\n",
    "#include \"tensorflow/core/framework/tensor_types.h\"\n",
    "#include \"tensorflow/core/framework/types.h\"\n",
    "#include \"tensorflow/core/kernels/bounds_check.h\"\n",
    "#include \"tensorflow/core/platform/logging.h\"\n",
    "#include \"tensorflow/core/platform/macros.h\"\n",
    "\n",
    "namespace tensorflow {\n",
    "\n",
    "typedef Eigen::ThreadPoolDevice CPUDevice;\n",
    "typedef Eigen::GpuDevice GPUDevice;\n",
    "\n",
    "template <typename Device, typename T, typename Tout, typename ArgFunctor>\n",
    "class ArgOp : public OpKernel {\n",
    " public:\n",
    "  explicit ArgOp(OpKernelConstruction* context) : OpKernel(context) {}\n",
    "\n",
    "  void Compute(OpKernelContext* context) override {\n",
    "    const Tensor& input = context->input(0);\n",
    "    const Tensor& dimension = context->input(1);\n",
    "\n",
    "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(dimension.shape()),\n",
    "                errors::InvalidArgument(\n",
    "                    \"dim must be a scalar, but received tensor of shape: \",\n",
    "                    dimension.shape().DebugString()));\n",
    "\n",
    "    const int32 dim = internal::SubtleMustCopy(dimension.scalar<int32>()());\n",
    "    const int input_dims = input.dims();\n",
    "\n",
    "    int axis = dim < 0 ? dim + input_dims : dim;\n",
    "\n",
    "    OP_REQUIRES(context, axis >= 0 && axis < input_dims,\n",
    "                errors::InvalidArgument(\"Expected dimension in the range [\",\n",
    "                                        -input_dims, \", \", input_dims,\n",
    "                                        \"), but got \", dim));\n",
    "    OP_REQUIRES(\n",
    "        context, input.dim_size(axis) > 0,\n",
    "        errors::InvalidArgument(\"Reduction axis \", dim, \" is empty in shape \",\n",
    "                                input.shape().DebugString()));\n",
    "\n",
    "    TensorShape output_shape;\n",
    "    const TensorShape& input_shape = input.shape();\n",
    "    for (int d = 0; d < input_dims - 1; ++d) {\n",
    "      output_shape.AddDim(input_shape.dim_size((d < axis) ? d : d + 1));\n",
    "    }\n",
    "    Tensor* output = nullptr;\n",
    "    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n",
    "\n",
    "#define HANDLE_DIM(NDIM)                                        \\\n",
    "  case NDIM:                                                    \\\n",
    "    ArgFunctor::Reduce##NDIM(context->eigen_device<Device>(),   \\\n",
    "                             input.tensor<T, NDIM>(), axis,     \\\n",
    "                             output->tensor<Tout, NDIM - 1>()); \\\n",
    "    break;\n",
    "\n",
    "    switch (input_dims) {\n",
    "      HANDLE_DIM(1);\n",
    "      HANDLE_DIM(2);\n",
    "      HANDLE_DIM(3);\n",
    "      HANDLE_DIM(4);\n",
    "      HANDLE_DIM(5);\n",
    "\n",
    "      default:\n",
    "        OP_REQUIRES(context, false,\n",
    "                    errors::InvalidArgument(\n",
    "                        \"ArgOp : Unhandled input dimensions: \", input_dims));\n",
    "    }\n",
    "  }\n",
    "#undef HANDLE_DIM\n",
    "\n",
    " private:\n",
    "  TF_DISALLOW_COPY_AND_ASSIGN(ArgOp);\n",
    "};\n",
    "\n",
    "template <typename Device, typename T, typename Tout>\n",
    "class ArgMaxOp\n",
    "    : public ArgOp<Device, T, Tout, functor::ArgMax<Device, T, Tout> > {\n",
    " public:\n",
    "  explicit ArgMaxOp(OpKernelConstruction* context)\n",
    "      : ArgOp<Device, T, Tout, functor::ArgMax<Device, T, Tout> >(context) {}\n",
    "};\n",
    "\n",
    "template <typename Device, typename T, typename Tout>\n",
    "class ArgMinOp\n",
    "    : public ArgOp<Device, T, Tout, functor::ArgMin<Device, T, Tout> > {\n",
    " public:\n",
    "  explicit ArgMinOp(OpKernelConstruction* context)\n",
    "      : ArgOp<Device, T, Tout, functor::ArgMin<Device, T, Tout> >(context) {}\n",
    "};\n",
    "\n",
    "#define REGISTER_ARGMAX(type)                                       \\\n",
    "  REGISTER_KERNEL_BUILDER(Name(\"ArgMax\")                            \\\n",
    "                              .Device(DEVICE_CPU)                   \\\n",
    "                              .TypeConstraint<type>(\"T\")            \\\n",
    "                              .TypeConstraint<int64>(\"output_type\") \\\n",
    "                              .HostMemory(\"dimension\"),             \\\n",
    "                          ArgMaxOp<CPUDevice, type, int64>);        \\\n",
    "  REGISTER_KERNEL_BUILDER(Name(\"ArgMin\")                            \\\n",
    "                              .Device(DEVICE_CPU)                   \\\n",
    "                              .TypeConstraint<type>(\"T\")            \\\n",
    "                              .TypeConstraint<int64>(\"output_type\") \\\n",
    "                              .HostMemory(\"dimension\"),             \\\n",
    "                          ArgMinOp<CPUDevice, type, int64>);        \\\n",
    "  REGISTER_KERNEL_BUILDER(Name(\"ArgMax\")                            \\\n",
    "                              .Device(DEVICE_CPU)                   \\\n",
    "                              .TypeConstraint<type>(\"T\")            \\\n",
    "                              .TypeConstraint<int32>(\"output_type\") \\\n",
    "                              .HostMemory(\"dimension\"),             \\\n",
    "                          ArgMaxOp<CPUDevice, type, int32>);        \\\n",
    "  REGISTER_KERNEL_BUILDER(Name(\"ArgMin\")                            \\\n",
    "                              .Device(DEVICE_CPU)                   \\\n",
    "                              .TypeConstraint<type>(\"T\")            \\\n",
    "                              .TypeConstraint<int32>(\"output_type\") \\\n",
    "                              .HostMemory(\"dimension\"),             \\\n",
    "                          ArgMinOp<CPUDevice, type, int32>);\n",
    "\n",
    "TF_CALL_REAL_NUMBER_TYPES(REGISTER_ARGMAX);\n",
    "\n",
    "#if GOOGLE_CUDA\n",
    "\n",
    "// Forward declarations of the functor specializations for GPU.\n",
    "namespace functor {\n",
    "\n",
    "#define DECLARE_GPU_SPEC(T, Tout, Dims)                                       \\\n",
    "  template <>                                                                 \\\n",
    "  void ArgMax<GPUDevice, T, Tout>::Reduce##Dims(                              \\\n",
    "      const GPUDevice& d, typename TTypes<T, Dims>::ConstTensor input,        \\\n",
    "      const int32 dimension, typename TTypes<Tout, Dims - 1>::Tensor output); \\\n",
    "  template <>                                                                 \\\n",
    "  void ArgMin<GPUDevice, T, Tout>::Reduce##Dims(                              \\\n",
    "      const GPUDevice& d, typename TTypes<T, Dims>::ConstTensor input,        \\\n",
    "      const int32 dimension, typename TTypes<Tout, Dims - 1>::Tensor output);\n",
    "\n",
    "#define DECLARE_GPU_SPECS(T)     \\\n",
    "  DECLARE_GPU_SPEC(T, int64, 1); \\\n",
    "  DECLARE_GPU_SPEC(T, int64, 2); \\\n",
    "  DECLARE_GPU_SPEC(T, int64, 3); \\\n",
    "  DECLARE_GPU_SPEC(T, int64, 4); \\\n",
    "  DECLARE_GPU_SPEC(T, int64, 5); \\\n",
    "  DECLARE_GPU_SPEC(T, int32, 1); \\\n",
    "  DECLARE_GPU_SPEC(T, int32, 2); \\\n",
    "  DECLARE_GPU_SPEC(T, int32, 3); \\\n",
    "  DECLARE_GPU_SPEC(T, int32, 4); \\\n",
    "  DECLARE_GPU_SPEC(T, int32, 5);\n",
    "\n",
    "#define DECLARE_GPU_CLASS(T)                          \\\n",
    "  extern template struct ArgMax<GPUDevice, T, int64>; \\\n",
    "  extern template struct ArgMin<GPUDevice, T, int64>; \\\n",
    "  extern template struct ArgMax<GPUDevice, T, int32>; \\\n",
    "  extern template struct ArgMin<GPUDevice, T, int32>;\n",
    "\n",
    "TF_CALL_GPU_NUMBER_TYPES(DECLARE_GPU_SPECS);\n",
    "TF_CALL_GPU_NUMBER_TYPES(DECLARE_GPU_CLASS);\n",
    "\n",
    "#undef DECLARE_GPU_SPECS\n",
    "#undef DECLARE_GPU_CLASS\n",
    "\n",
    "}  // namespace functor\n",
    "\n",
    "// Registration of the GPU implementations.\n",
    "#define REGISTER_ARGMAX_GPU(type)                                   \\\n",
    "  REGISTER_KERNEL_BUILDER(Name(\"ArgMax\")                            \\\n",
    "                              .Device(DEVICE_GPU)                   \\\n",
    "                              .TypeConstraint<type>(\"T\")            \\\n",
    "                              .TypeConstraint<int64>(\"output_type\") \\\n",
    "                              .TypeConstraint<int32>(\"Tidx\")        \\\n",
    "                              .HostMemory(\"dimension\"),             \\\n",
    "                          ArgMaxOp<GPUDevice, type, int64>);        \\\n",
    "  REGISTER_KERNEL_BUILDER(Name(\"ArgMin\")                            \\\n",
    "                              .Device(DEVICE_GPU)                   \\\n",
    "                              .TypeConstraint<type>(\"T\")            \\\n",
    "                              .TypeConstraint<int64>(\"output_type\") \\\n",
    "                              .TypeConstraint<int32>(\"Tidx\")        \\\n",
    "                              .HostMemory(\"dimension\"),             \\\n",
    "                          ArgMinOp<GPUDevice, type, int64>);        \\\n",
    "  REGISTER_KERNEL_BUILDER(Name(\"ArgMax\")                            \\\n",
    "                              .Device(DEVICE_GPU)                   \\\n",
    "                              .TypeConstraint<type>(\"T\")            \\\n",
    "                              .TypeConstraint<int32>(\"output_type\") \\\n",
    "                              .TypeConstraint<int32>(\"Tidx\")        \\\n",
    "                              .HostMemory(\"dimension\"),             \\\n",
    "                          ArgMaxOp<GPUDevice, type, int32>);        \\\n",
    "  REGISTER_KERNEL_BUILDER(Name(\"ArgMin\")                            \\\n",
    "                              .Device(DEVICE_GPU)                   \\\n",
    "                              .TypeConstraint<type>(\"T\")            \\\n",
    "                              .TypeConstraint<int32>(\"output_type\") \\\n",
    "                              .TypeConstraint<int32>(\"Tidx\")        \\\n",
    "                              .HostMemory(\"dimension\"),             \\\n",
    "                          ArgMinOp<GPUDevice, type, int32>);\n",
    "\n",
    "TF_CALL_GPU_NUMBER_TYPES(REGISTER_ARGMAX_GPU);\n",
    "\n",
    "#undef REGISTER_ARGMAX_GPU\n",
    "\n",
    "#endif  // GOOGLE_CUDA\n",
    "\n",
    "}  // namespace tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:libspn]",
   "language": "python",
   "name": "conda-env-libspn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
