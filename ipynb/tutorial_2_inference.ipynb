{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libspn as spn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Test Graph with Initialized Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_x = spn.IVs(num_vars=2, num_vals=2, name=\"iv_x\")\n",
    "\n",
    "# Note that inputs are given as tuples (node, indices)\n",
    "sum_11 = spn.Sum((iv_x, [0,1]), name=\"sum_11\")\n",
    "sum_11.generate_weights([0.4, 0.6])\n",
    "# Again same node, same indices\n",
    "sum_12 = spn.Sum((iv_x, [0,1]), name=\"sum_12\")\n",
    "sum_12.generate_weights([0.1, 0.9])\n",
    "# Same node, but second IV\n",
    "sum_21 = spn.Sum((iv_x, [2,3]), name=\"sum_21\")\n",
    "sum_21.generate_weights([0.7, 0.3])\n",
    "sum_22 = spn.Sum((iv_x, [2,3]), name=\"sum_22\")\n",
    "sum_22.generate_weights([0.8, 0.2])\n",
    "\n",
    "# Product node, taking sum nodes of IV1;1 and IV2;1\n",
    "prod_1 = spn.Product(sum_11, sum_21, name=\"prod_1\")\n",
    "# Product node, taking sum nodes of IV1;1 and IV2;2\n",
    "prod_2 = spn.Product(sum_11, sum_22, name=\"prod_2\")\n",
    "# ...\n",
    "prod_3 = spn.Product(sum_12, sum_22, name=\"prod_3\")\n",
    "root = spn.Sum(prod_1, prod_2, prod_3, name=\"root\")\n",
    "root.generate_weights([0.5, 0.2, 0.3])\n",
    "iv_y = root.generate_ivs(name=\"iv_y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the SPN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg id=\"Se0382758df8546b396a0ff2203ede2aa\" width=\"950\" height=\"800\"></svg>\n",
       "<script>\n",
       " require.config({\n",
       "   paths: {\n",
       "     d3: 'https://d3js.org/d3.v4.min'\n",
       "   }\n",
       " });\n",
       " require(['d3'], function(d3){\n",
       "\n",
       "   var graph = {\"links\": [{\"target\": \"sum_22_1\", \"value\": 2, \"source\": \"sum_22_1_Weights_1\"}, {\"target\": \"sum_22_1\", \"value\": 2, \"source\": \"iv_x_1_2\"}, {\"target\": \"sum_12_1\", \"value\": 2, \"source\": \"sum_12_1_Weights_3\"}, {\"target\": \"sum_12_1\", \"value\": 2, \"source\": \"iv_x_1_4\"}, {\"target\": \"prod_3_1\", \"value\": 1, \"source\": \"sum_12_1\"}, {\"target\": \"prod_3_1\", \"value\": 1, \"source\": \"sum_22_1\"}, {\"target\": \"sum_11_1\", \"value\": 2, \"source\": \"sum_11_1_Weights_5\"}, {\"target\": \"sum_11_1\", \"value\": 2, \"source\": \"iv_x_1_6\"}, {\"target\": \"prod_2_1\", \"value\": 1, \"source\": \"sum_11_1\"}, {\"target\": \"prod_2_1\", \"value\": 1, \"source\": \"sum_22_1\"}, {\"target\": \"sum_21_1\", \"value\": 2, \"source\": \"sum_21_1_Weights_7\"}, {\"target\": \"sum_21_1\", \"value\": 2, \"source\": \"iv_x_1_8\"}, {\"target\": \"prod_1_1\", \"value\": 1, \"source\": \"sum_11_1\"}, {\"target\": \"prod_1_1\", \"value\": 1, \"source\": \"sum_21_1\"}, {\"target\": \"root_1\", \"value\": 3, \"source\": \"root_1_Weights_9\"}, {\"target\": \"root_1\", \"value\": 3, \"source\": \"iv_y_1_10\"}, {\"target\": \"root_1\", \"value\": 1, \"source\": \"prod_1_1\"}, {\"target\": \"root_1\", \"value\": 1, \"source\": \"prod_2_1\"}, {\"target\": \"root_1\", \"value\": 1, \"source\": \"prod_3_1\"}], \"nodes\": [{\"name\": \"sum_22_1\", \"type\": 2, \"id\": \"sum_22_1\", \"tooltip\": \"sum_22_1\"}, {\"name\": \"sum_22_1_Weights\", \"type\": 1, \"id\": \"sum_22_1_Weights_1\", \"tooltip\": \"sum_22_1_Weights\"}, {\"name\": \"iv_x_1[2, 3]\", \"type\": 0, \"id\": \"iv_x_1_2\", \"tooltip\": \"iv_x_1\"}, {\"name\": \"sum_12_1\", \"type\": 2, \"id\": \"sum_12_1\", \"tooltip\": \"sum_12_1\"}, {\"name\": \"sum_12_1_Weights\", \"type\": 1, \"id\": \"sum_12_1_Weights_3\", \"tooltip\": \"sum_12_1_Weights\"}, {\"name\": \"iv_x_1[0, 1]\", \"type\": 0, \"id\": \"iv_x_1_4\", \"tooltip\": \"iv_x_1\"}, {\"name\": \"prod_3_1\", \"type\": 3, \"id\": \"prod_3_1\", \"tooltip\": \"prod_3_1\"}, {\"name\": \"sum_11_1\", \"type\": 2, \"id\": \"sum_11_1\", \"tooltip\": \"sum_11_1\"}, {\"name\": \"sum_11_1_Weights\", \"type\": 1, \"id\": \"sum_11_1_Weights_5\", \"tooltip\": \"sum_11_1_Weights\"}, {\"name\": \"iv_x_1[0, 1]\", \"type\": 0, \"id\": \"iv_x_1_6\", \"tooltip\": \"iv_x_1\"}, {\"name\": \"prod_2_1\", \"type\": 3, \"id\": \"prod_2_1\", \"tooltip\": \"prod_2_1\"}, {\"name\": \"sum_21_1\", \"type\": 2, \"id\": \"sum_21_1\", \"tooltip\": \"sum_21_1\"}, {\"name\": \"sum_21_1_Weights\", \"type\": 1, \"id\": \"sum_21_1_Weights_7\", \"tooltip\": \"sum_21_1_Weights\"}, {\"name\": \"iv_x_1[2, 3]\", \"type\": 0, \"id\": \"iv_x_1_8\", \"tooltip\": \"iv_x_1\"}, {\"name\": \"prod_1_1\", \"type\": 3, \"id\": \"prod_1_1\", \"tooltip\": \"prod_1_1\"}, {\"name\": \"root_1\", \"type\": 2, \"id\": \"root_1\", \"tooltip\": \"root_1\"}, {\"name\": \"root_1_Weights\", \"type\": 1, \"id\": \"root_1_Weights_9\", \"tooltip\": \"root_1_Weights\"}, {\"name\": \"iv_y_1\", \"type\": 0, \"id\": \"iv_y_1_10\", \"tooltip\": \"iv_y_1\"}]};\n",
       "\n",
       "   var color = d3.scaleOrdinal(d3.schemeCategory10);\n",
       "\n",
       "   var zoom = d3.zoom()\n",
       "                .scaleExtent([0.1, 10])\n",
       "                .on(\"zoom\", zoomed);\n",
       "\n",
       "   var svg = d3.select(\"#Se0382758df8546b396a0ff2203ede2aa\").\n",
       "                call(zoom);\n",
       "\n",
       "   var width = svg.attr(\"width\");\n",
       "   var height = svg.attr(\"height\");\n",
       "\n",
       "   var simulation = d3.forceSimulation(graph.nodes)\n",
       "                      .on(\"tick\", ticked)\n",
       "                      .force(\"link\", d3.forceLink(graph.links)\n",
       "                                       .distance(80)\n",
       "                                       .id(function(d) { return d.id; }))\n",
       "                      .force(\"charge\", d3.forceManyBody().\n",
       "                                          strength(-1000))\n",
       "                      .force(\"center\", d3.forceCenter(width / 2, height / 2));\n",
       "\n",
       "   /* Contents */\n",
       "   var container = svg.append(\"g\").\n",
       "                       attr(\"class\", \"container\");\n",
       "\n",
       "   var link = container.append(\"g\")\n",
       "                       .selectAll(\"link\")\n",
       "                       .data(graph.links)\n",
       "                       .enter().append(\"line\")\n",
       "                       .attr(\"stroke\", \"#444\")\n",
       "                       .attr(\"stroke-opacity\", \"0.6\")\n",
       "                       .attr(\"stroke-width\",\n",
       "                             function(d) {\n",
       "                               return d.value;\n",
       "                               /*return Math.sqrt(d.value);*/\n",
       "                             });\n",
       "\n",
       "   var link_value = container.append(\"g\")\n",
       "                             .selectAll(\"linkvalue\")\n",
       "                             .data(graph.links)\n",
       "                             .enter().append(\"text\")\n",
       "                             .attr(\"alignment-baseline\", \"middle\")\n",
       "                             .style(\"text-anchor\", \"middle\")\n",
       "                             .text(function(d) { return d.value; });\n",
       "\n",
       "   var node = container.append(\"g\")\n",
       "                       .selectAll(\"node\")\n",
       "                       .data(graph.nodes)\n",
       "                       .enter().append(\"g\")\n",
       "                       .call(d3.drag()\n",
       "                               .on(\"start\", dragstarted)\n",
       "                               .on(\"drag\", dragged)\n",
       "                               .on(\"end\", dragended));\n",
       "\n",
       "   /* Node appearance */\n",
       "   node.append(\"rect\")\n",
       "       .attr(\"height\", 0)\n",
       "       .attr(\"width\", 0)\n",
       "       .attr(\"fill\", function(d) { return color(d.type); })\n",
       "       .attr(\"stroke\", \"#000\")\n",
       "       .attr(\"stroke-width\", \"1px\");\n",
       "\n",
       "   node.append(\"text\")\n",
       "       .attr(\"alignment-baseline\", \"middle\")\n",
       "       .style(\"text-anchor\", \"middle\")\n",
       "       .text(function(d) { return d.name; });\n",
       "\n",
       "   /* Adjust rect width to text */\n",
       "   var margin=10;\n",
       "   node.selectAll('rect')\n",
       "       .attr(\"x\", function(d) {return d3.select(this).attr(\"x\") - (this.parentNode.getBBox().width + margin)/2.0;})\n",
       "       .attr(\"y\", function(d) {return d3.select(this).attr(\"y\") - (this.parentNode.getBBox().height + margin)/2.0;})\n",
       "       .attr(\"width\", function(d) {return this.parentNode.getBBox().width + margin;})\n",
       "       .attr(\"height\", function(d) {return this.parentNode.getBBox().height + margin;});\n",
       "\n",
       "   /* Tooltips */\n",
       "   node.append(\"title\")\n",
       "       .text(function(d) { return d.tooltip; });\n",
       "\n",
       "   /* Functions */\n",
       "   function zoomed() {\n",
       "     container.attr(\"transform\", d3.event.transform);\n",
       "   }\n",
       "\n",
       "   function ticked() {\n",
       "     link\n",
       "       .attr(\"x1\", function(d) { return d.source.x; })\n",
       "       .attr(\"y1\", function(d) { return d.source.y; })\n",
       "       .attr(\"x2\", function(d) { return d.target.x; })\n",
       "       .attr(\"y2\", function(d) { return d.target.y; });\n",
       "\n",
       "     link_value\n",
       "       .attr(\"x\", function(d) { return (d.source.x+d.target.x)/2; })\n",
       "       .attr(\"y\", function(d) { return (d.source.y+d.target.y)/2; })\n",
       "\n",
       "     node.attr(\"transform\",\n",
       "               function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "   }\n",
       "\n",
       "   function dragstarted(d) {\n",
       "     if (!d3.event.active) simulation.alphaTarget(0.3).restart();\n",
       "     d.fx = d.x;\n",
       "     d.fy = d.y;\n",
       "   }\n",
       "\n",
       "   function dragged(d) {\n",
       "     d.fx = d3.event.x;\n",
       "     d.fy = d3.event.y;\n",
       "   }\n",
       "\n",
       "   function dragended(d) {\n",
       "     if (!d3.event.active) simulation.alphaTarget(0);\n",
       "     d.fx = null;\n",
       "     d.fy = null;\n",
       "   }\n",
       "\n",
       " });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spn.display_spn_graph(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Value Ops\n",
    "Now generate marginals and MPE ops. Internally a `Value` class is instantiated that is given a specific `InferenceType`. Then, `Value(inference_type).get_value(self)` is called, where `self` is the root node. implementation of `get_value`:\n",
    "```python\n",
    "    class Value:\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "\n",
    "        def get_value(self, root):\n",
    "            \"\"\"Assemble a TF operation computing the values of nodes of the SPN\n",
    "            rooted in ``root``.\n",
    "\n",
    "            Returns the operation computing the value for the ``root``. Operations\n",
    "            computing values for other nodes can be obtained using :obj:`values`.\n",
    "\n",
    "            Args:\n",
    "                root (Node): The root node of the SPN graph.\n",
    "\n",
    "            Returns:\n",
    "                Tensor: A tensor of shape ``[None, num_outputs]``, where the first\n",
    "                dimension corresponds to the batch size.\n",
    "            \"\"\"\n",
    "            def fun(node, *args):\n",
    "                with tf.name_scope(node.name):\n",
    "                    if (self._inference_type == InferenceType.MARGINAL\n",
    "                        or (self._inference_type is None and\n",
    "                            node.inference_type == InferenceType.MARGINAL)):\n",
    "                        return node._compute_value(*args)\n",
    "                    else:\n",
    "                        return node._compute_mpe_value(*args)\n",
    "\n",
    "            self._values = {}\n",
    "            with tf.name_scope(\"Value\"):\n",
    "                return compute_graph_up(root, val_fun=fun,\n",
    "                                        all_values=self._values)\n",
    "    ```\n",
    "\n",
    "And the implementation of `compute_graph_up`:\n",
    "```python\n",
    "\n",
    "def compute_graph_up(root, val_fun, const_fun=None, all_values=None):\n",
    "    \"\"\"Computes a certain value for the ``root`` node in the graph, assuming\n",
    "    that for op nodes, the value depends on values produced by inputs of the op\n",
    "    node. For this, it traverses the graph depth-first from the ``root`` node\n",
    "    to the leaf nodes.\n",
    "\n",
    "    Args:\n",
    "        root (Node): The root of the SPN graph.\n",
    "        val_fun (function): A function ``val_fun(node, *args)`` producing a\n",
    "            certain value for the ``node``. For an op node, it will have\n",
    "            additional arguments with values produced for the input nodes of\n",
    "            ``node``.  The arguments will NOT be added if ``const_fun``\n",
    "            returns ``True`` for the node. The arguments can be ``None`` if\n",
    "            the input was empty.\n",
    "        const_fun (function): A function ``const_fun(node)`` that should return\n",
    "            ``True`` if the value generated by ``val_fun`` does not depend on\n",
    "            the values generated for the input nodes, i.e. it is a constant\n",
    "            function. If set to ``None``, it is assumed to always return\n",
    "            ``False``, i.e. no ``val_fun`` is a constant function.\n",
    "        all_values (dict): A dictionary indexed by ``node`` in which values\n",
    "            computed for each node will be stored. Can be set to ``None``.\n",
    "\n",
    "    Returns:\n",
    "        The value for the ``root`` node.\n",
    "    \"\"\"\n",
    "    if all_values is None:  # Dictionary of computed values indexed by node\n",
    "        all_values = {}\n",
    "    stack = deque()  # Stack of nodes to process\n",
    "    stack.append(root)\n",
    "\n",
    "    last_val = None\n",
    "    while stack:\n",
    "        next_node = stack[-1]\n",
    "        # Was this node already processed?\n",
    "        # This might happen if the node is referenced by several parents\n",
    "        if next_node not in all_values:\n",
    "            if next_node.is_op:\n",
    "                # OpNode\n",
    "                input_vals = []\n",
    "                all_input_vals = True\n",
    "                if const_fun is None or const_fun(next_node) is False:\n",
    "                    # Gather input values for non-const val fun\n",
    "                    for inpt in next_node.inputs:\n",
    "                        if inpt:  # Input is not empty\n",
    "                            try:\n",
    "                                # Check if input_node in all_vals\n",
    "                                input_vals.append(all_values[inpt.node])\n",
    "                            except KeyError:\n",
    "                                \"\"\" At least one input is missing \"\"\"\n",
    "                                all_input_vals = False\n",
    "                                stack.append(inpt.node)\n",
    "                        else:\n",
    "                            # This input was empty, use None as value\n",
    "                            \"\"\" When can an input be empty? \"\"\"\n",
    "                            input_vals.append(None)\n",
    "                # Got all inputs?\n",
    "                if all_input_vals:\n",
    "                    \"\"\" This is where val_fun is called, which itselfs chooses MPE or marginal \"\"\"\n",
    "                    last_val = val_fun(next_node, *input_vals)\n",
    "                    all_values[next_node] = last_val\n",
    "                    stack.pop()\n",
    "            else:\n",
    "                # VarNode, ParamNode\n",
    "                \"\"\" VarNode and ParamNode don't have their own inputs, so we don't have *input_vals \"\"\"\n",
    "                last_val = val_fun(next_node)\n",
    "                all_values[next_node] = last_val\n",
    "                stack.pop()\n",
    "        else:\n",
    "            stack.pop()\n",
    "\n",
    "    return last_val\n",
    "```\n",
    "\n",
    "So what are the MPE and marginal functions in `Node`? Well, take `ProdNode`'s implementation:\n",
    "```python\n",
    "def _compute_mpe_path(self, counts, *value_values, add_random=False, use_unweighted=False):\n",
    "    \"\"\" Note sure what value_values could be, should just be input_values (right?) \"\"\"\n",
    "    # Check inputs\n",
    "    if not self._values:\n",
    "        raise StructureError(\"%s is missing input values.\" % self)\n",
    "\n",
    "    def process_input(v_input, v_value):\n",
    "        \"\"\" Get size of v_value tensor, if v_input.indices is set just returns len(v_input) \"\"\"\n",
    "        input_size = v_input.get_size(v_value)\n",
    "        # Tile the counts if input is larger than 1\n",
    "        \"\"\" \n",
    "        Tiling is used for separating counting across minibatch I guess. It tiles \n",
    "        `counts` once along the first axis, and `input_size` times along second axis, \n",
    "        meaning for each of these inputs, it provides a slot initialized at the value \n",
    "        of `counts`\n",
    "        \"\"\"\n",
    "        return (tf.tile(counts, [1, input_size])\n",
    "                if input_size > 1 else counts)\n",
    "\n",
    "    # For each input, pass counts to all elements selected by indices\n",
    "    value_counts = [(process_input(v_input, v_value), v_value)\n",
    "                    for v_input, v_value\n",
    "                    in zip(self._values, value_values)]\n",
    "    # TODO: Scatter to input tensors can be merged with tiling to reduce\n",
    "    # the amount of operations.\n",
    "        \n",
    "    \"\"\" Returns an op that scatters the counts to input nodes \"\"\"\n",
    "    return self._scatter_to_input_tensors(*value_counts)\n",
    "```\n",
    "\n",
    "Getting there, now let's see what `_scatter_to_input_tensors(*value_counts)` does:\n",
    "```python\n",
    "def _scatter_to_input_tensors(self, *tuples):\n",
    "    \"\"\"For each input, scatter the given tensor to elements indicated by\n",
    "    input indices. This reverses what ``gather_input_tensors`` is doing.\n",
    "    If input indices are ``None``, it adds no operations and forwards the\n",
    "    tensor as is. If the input is disconnected or ``None`` is given in\n",
    "    ``*tuples``, ``None`` is returned for that input.\n",
    "\n",
    "    Args:\n",
    "        *tuples (tuple): For each input, a tuple ``(tensor, input_tensor)``,\n",
    "            where ``tensor`` is the tensor to be scattered, and\n",
    "            ``input_tensor`` is the tensor produced by the input node. The\n",
    "            second tensor is used only to retrieve the appropriate dimensions.\n",
    "\n",
    "    Returns:\n",
    "        list of Tensor: A list of tensors containing scattered values.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"scatter_to_input_tensors\", values=[t[0] for t in tuples]):\n",
    "        return tuple(None if not i or t is None          # (None, ...)\n",
    "                     else t[0] if i.indices is None      # (t[0], ...) first element of tuple\n",
    "                     else utils.scatter_cols(            # utils.scatter_cols(t[0], i.indices)\n",
    "                         t[0], i.indices,\n",
    "                         int(t[1].get_shape()\n",
    "                             [0 if t[1].get_shape().ndims == 1 else 1]))\n",
    "                     for i, t in zip(self.inputs, tuples))\n",
    "\n",
    "```\n",
    "So this returns a (potentially large) tuple containing either `None`, `t[0]` or some scatter col Op. The scatter col python binding is:\n",
    "\n",
    "```python\n",
    "def scatter_cols(params, indices, num_out_cols, name=None):\n",
    "    \"\"\"Scatter columns of a 2D tensor or values of a 1D tensor into a tensor\n",
    "    with the same number of dimensions and ``num_out_cols`` columns or values.\n",
    "\n",
    "    Args:\n",
    "        params (Tensor): A 1D or 2D tensor.\n",
    "        indices (array_like): A 1D integer array indexing the columns in the\n",
    "                              output array to which ``params`` is scattered.\n",
    "        num_cols (int): The number of columns in the output tensor.\n",
    "        name (str): A name for the operation (optional).\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Has the same dtype and number of dimensions as ``params``.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, \"scatter_cols\", [params, indices]):\n",
    "        # Check input\n",
    "        params = tf.convert_to_tensor(params, name=\"params\")\n",
    "        indices = np.asarray(indices)\n",
    "        # Check params\n",
    "        param_shape = params.get_shape()\n",
    "        param_dims = param_shape.ndims\n",
    "        if param_dims == 1:\n",
    "            param_size = param_shape[0].value\n",
    "        elif param_dims == 2:\n",
    "            param_size = param_shape[1].value\n",
    "        else:\n",
    "            raise ValueError(\"'params' must be 1D or 2D\")\n",
    "        # We need the size defined for optimizations\n",
    "        if param_size is None:\n",
    "            raise RuntimeError(\"The indexed dimension of 'params' is not specified\")\n",
    "        # Check num_out_cols\n",
    "        if not isinstance(num_out_cols, int):\n",
    "            raise ValueError(\"'num_out_cols' must be integer, not %s\"\n",
    "                             % type(num_out_cols))\n",
    "        if num_out_cols < param_size:\n",
    "            raise ValueError(\"'num_out_cols' must be larger than the size of \"\n",
    "                             \"the indexed dimension of 'params'\")\n",
    "        # Check indices\n",
    "        if indices.ndim != 1:\n",
    "            raise ValueError(\"'indices' must be 1D\")\n",
    "        if indices.size != param_size:\n",
    "            raise ValueError(\"Sizes of 'indices' and the indexed dimension of \"\n",
    "                             \"'params' must be the same\")\n",
    "        if not np.issubdtype(indices.dtype, np.integer):\n",
    "            raise ValueError(\"'indices' must be integer, not %s\"\n",
    "                             % indices.dtype)\n",
    "        if np.any((indices < 0) | (indices >= num_out_cols)):\n",
    "            raise ValueError(\"'indices' must be smaller than 'num_out_cols'\")\n",
    "        if len(set(indices)) != len(indices):\n",
    "            raise ValueError(\"'indices' cannot contain duplicates\")\n",
    "        # Define op\n",
    "        if num_out_cols == 1:\n",
    "            # Scatter to a single column tensor, it must be from 1 column\n",
    "            # tensor and the indices must include it. Just forward the tensor.\n",
    "            return params\n",
    "        elif num_out_cols == indices.size and np.all(np.ediff1d(indices) == 1):\n",
    "            # Output equals input\n",
    "            return params\n",
    "        elif param_size == 1:\n",
    "            # Scatter a single column tensor to a multi-column tensor\n",
    "            if param_dims == 1:\n",
    "                # Just pad with zeros, pad is fastest and offers smallest graph\n",
    "                return tf.pad(params, [[indices[0], num_out_cols - indices[0] - 1]])\n",
    "            else:\n",
    "                # Currently pad is fastest (for GPU) and builds smaller graph\n",
    "                # if conf.custom_scatter_cols:\n",
    "                #     return ops.scatter_cols(\n",
    "                #         params, indices,\n",
    "                #         pad_elem=tf.constant(0, dtype=params.dtype),\n",
    "                #         num_out_col=num_out_cols)\n",
    "                # else:\n",
    "                return tf.pad(params, [[0, 0],\n",
    "                                       [indices[0], num_out_cols - indices[0] - 1]])\n",
    "        else:\n",
    "            # Scatter a multi-column tensor to a multi-column tensor\n",
    "            if param_dims == 1:\n",
    "                # Use custom built op\n",
    "                if conf.custom_scatter_cols:\n",
    "                    return ops.scatter_cols(\n",
    "                        params, indices,\n",
    "                        pad_elem=tf.constant(0, dtype=params.dtype),\n",
    "                        num_out_col=num_out_cols)\n",
    "                else:\n",
    "                    # add zero on first axis                                               \n",
    "                    with_zeros = tf.concat(values=([0], params), axis=0)\n",
    "                    # Init zero array for gathering indices\n",
    "                    gather_indices = np.zeros(num_out_cols, dtype=int)\n",
    "                    # Set gathering indices as a list [1, ..., indices.size]\n",
    "                    # So we gather with a zero prepended to make sure we take a larger\n",
    "                    # tensor to a smaller one?\n",
    "                    gather_indices[indices] = np.arange(indices.size) + 1\n",
    "                    # Use gather cols\n",
    "                    return gather_cols(with_zeros, gather_indices)\n",
    "            else:\n",
    "                if conf.custom_scatter_cols:\n",
    "                    # Use custom built op\n",
    "                    return ops.scatter_cols(\n",
    "                        params, indices,\n",
    "                        pad_elem=tf.constant(0, dtype=params.dtype),\n",
    "                        num_out_col=num_out_cols)\n",
    "                else:\n",
    "                    # Set zero columns\n",
    "                    zero_col = tf.zeros((tf.shape(params)[0], 1),\n",
    "                                        dtype=params.dtype)\n",
    "                    # Concat zeros with\n",
    "                    with_zeros = tf.concat(values=(zero_col, params), axis=1)\n",
    "                    gather_indices = np.zeros(num_out_cols, dtype=int)\n",
    "                    gather_indices[indices] = np.arange(indices.size) + 1\n",
    "                    return gather_cols(with_zeros, gather_indices)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the assign operation by gathering init ops from nodes\n",
    "init_weights = spn.initialize_weights(root)\n",
    "\n",
    "# Generates marginal val op\n",
    "marginal_val = root.get_value(inference_type=spn.InferenceType.MARGINAL)\n",
    "mpe_val = root.get_value(inference_type=spn.InferenceType.MPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.082     ]\n",
      " [ 0.52200001]\n",
      " [ 0.69      ]\n",
      " [ 1.        ]]\n",
      "[[ 0.06      ]\n",
      " [ 0.21600001]\n",
      " [ 0.21600001]\n",
      " [ 0.21600001]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iv_x_arr = [[0, 1], # iv1 = 0, iv2 = 1\n",
    "           [1, 0],  # iv1 = 1, iv2 = 0\n",
    "           [1,-1],  # iv1 = 1, iv2 = NOEVIDENCE\n",
    "           [-1,-1]] # iv1 = iv2 = NOEVIDENCE\n",
    "\n",
    "iv_y_arr = [[-1]] * 4\n",
    "\n",
    "with spn.session() as (sess, _):\n",
    "    init_weights.run()\n",
    "    marginal_val_arr = sess.run(marginal_val, feed_dict={iv_x: iv_x_arr, iv_y: iv_y_arr})\n",
    "    mpe_val_arr = sess.run(mpe_val, feed_dict={iv_x: iv_x_arr, iv_y: iv_y_arr})\n",
    "    \n",
    "print(marginal_val_arr)\n",
    "print(mpe_val_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add MPE State Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpe_state_gen = spn.MPEState(value_inference_type=spn.InferenceType.MPE)\n",
    "iv_x_state, iv_y_state = mpe_state_gen.get_state(root, iv_x, iv_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]]\n",
      "[[2]]\n"
     ]
    }
   ],
   "source": [
    "with spn.session() as (sess, _):\n",
    "    init_weights.run()\n",
    "    iv_x_state_arr, iv_y_state_arr = sess.run([iv_x_state, iv_y_state], \n",
    "                                              feed_dict={iv_x: [[-1,-1]], \n",
    "                                                         iv_y: [[-1]]})\n",
    "    \n",
    "print(iv_x_state_arr)\n",
    "print(iv_y_state_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
